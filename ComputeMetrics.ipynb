{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIfC2S6gaKTr"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVYl1HFZSDad"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "from dataclasses import dataclass\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from time import sleep\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pandas as pd\n",
        "\n",
        "RESULTS_DIR = Path(\"./\")\n",
        "OUTPUT_DIR = Path(\"./reprocessed_results\")\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE6j4X0TSGmH"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class PairResult:\n",
        "    pair_id: int\n",
        "    commit_id: str\n",
        "    ground_truth_cwe: str\n",
        "    vuln_detected_cwes: List[str]\n",
        "    fixed_detected_cwes: List[str]\n",
        "\n",
        "json_file = RESULTS_DIR / \"YOUR_RESULTS_FILE.json\"\n",
        "\n",
        "with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(f\"Number of pairs: {len(data['pairs'])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMMv10HBSMPB"
      },
      "outputs": [],
      "source": [
        "cwe_set = set()\n",
        "\n",
        "for pair in data[\"pairs\"]:\n",
        "    gt = pair.get(\"ground_truth_cwe\")\n",
        "    if gt:\n",
        "        cwe_set.add(gt)\n",
        "    vuln_cwes = pair.get(\"vulnerable\", {}).get(\"detected_cwes\", [])\n",
        "    fixed_cwes = pair.get(\"fixed\", {}).get(\"detected_cwes\", [])\n",
        "    cwe_set.update(vuln_cwes)\n",
        "    cwe_set.update(fixed_cwes)\n",
        "\n",
        "cwe_list = sorted(cwe_set)\n",
        "print(f\"{len(cwe_list)} unique CWEs found.\")\n",
        "print(cwe_list[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYgHSmOASPoC"
      },
      "outputs": [],
      "source": [
        "BASE_URL = \"http://cwe.mitre.org/data/definitions/{}.html\"\n",
        "\n",
        "def fetch_cwe_description(cwe_id):\n",
        "    url = BASE_URL.format(cwe_id.split(\"-\")[1])\n",
        "    try:\n",
        "        r = requests.get(url)\n",
        "        if r.status_code != 200:\n",
        "            return None\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "        title_tag = soup.find(\"span\", {\"id\": \"TitleText\"})\n",
        "        name = title_tag.text.strip() if title_tag else \"\"\n",
        "        desc_tag = soup.find(\"div\", {\"id\": \"Description\"})\n",
        "        description = desc_tag.text.strip() if desc_tag else \"\"\n",
        "        return {\"cwe_id\": cwe_id, \"name\": name, \"description\": description}\n",
        "    except Exception as e:\n",
        "        print(f\"Error CWE-{cwe_id}: {e}\")\n",
        "        return None\n",
        "\n",
        "cwe_data = []\n",
        "for cwe_id in tqdm(cwe_list):\n",
        "    data_cwe = fetch_cwe_description(cwe_id)\n",
        "    if data_cwe:\n",
        "        cwe_data.append(data_cwe)\n",
        "    sleep(0.5)\n",
        "\n",
        "with open(OUTPUT_DIR / \"cwe_descriptions.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(cwe_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"{len(cwe_data)} CWE descriptions fetched and saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh0xsK0pSYH3"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "with open(OUTPUT_DIR / \"cwe_descriptions.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    cwe_descriptions = json.load(f)\n",
        "\n",
        "cwe_embeddings = {}\n",
        "for item in cwe_descriptions:\n",
        "    desc = item.get(\"description\", \"\")\n",
        "    if desc:\n",
        "        cwe_embeddings[item[\"cwe_id\"]] = model.encode(desc, convert_to_tensor=True)\n",
        "    else:\n",
        "        cwe_embeddings[item[\"cwe_id\"]] = torch.zeros(model.get_sentence_embedding_dimension())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lf67sVASSY-Q"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(data):\n",
        "    tp = tn = fp = fn = 0\n",
        "    pairs_correct = 0\n",
        "    pairs_reversed = 0\n",
        "    for pair in data[\"pairs\"]:\n",
        "        gt = pair[\"ground_truth_cwe\"]\n",
        "        vuln_detects = pair[\"vulnerable\"][\"detected_cwes\"]\n",
        "        fixed_detects = pair[\"fixed\"][\"detected_cwes\"]\n",
        "\n",
        "        vuln_tp = gt in vuln_detects\n",
        "        vuln_fn = not vuln_tp\n",
        "        fixed_fp = gt in fixed_detects\n",
        "        fixed_tn = not fixed_fp\n",
        "\n",
        "        tp += vuln_tp\n",
        "        fn += vuln_fn\n",
        "        tn += fixed_tn\n",
        "        fp += fixed_fp\n",
        "\n",
        "        if vuln_tp and fixed_tn:\n",
        "            pairs_correct += 1\n",
        "        elif vuln_fn and fixed_fp:\n",
        "            pairs_reversed += 1\n",
        "\n",
        "    total = tp + tn + fp + fn\n",
        "    accuracy = (tp + tn) / total if total > 0 else 0\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    vps = pairs_correct - pairs_reversed\n",
        "\n",
        "    return {\n",
        "        \"TP\": tp, \"TN\": tn, \"FP\": fp, \"FN\": fn, \"Total\": total,\n",
        "        \"P-C (Pairs Correct)\": pairs_correct,\n",
        "        \"P-R (Pairs Reversed)\": pairs_reversed,\n",
        "        \"VPS\": vps,\n",
        "        \"Accuracy\": round(accuracy,4),\n",
        "        \"Precision\": round(precision,4),\n",
        "        \"Recall\": round(recall,4),\n",
        "        \"F1-Score\": round(f1_score,4)\n",
        "    }\n",
        "\n",
        "metrics = calculate_metrics(data)\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8hZMBaSSemo"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(metrics):\n",
        "    cm = np.array([[metrics[\"TP\"], metrics[\"FN\"]],\n",
        "                   [metrics[\"FP\"], metrics[\"TN\"]]])\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=[\"Pred Vulnerable\",\"Pred Safe\"],\n",
        "                yticklabels=[\"Actual Vulnerable\",\"Actual Safe\"])\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps6-ou6CSjLT"
      },
      "outputs": [],
      "source": [
        "def compute_semantic_fn_tp(pair, cwe_embeddings):\n",
        "    gt_cwe = pair[\"ground_truth_cwe\"]\n",
        "    vuln_detected = pair[\"vulnerable\"][\"detected_cwes\"]\n",
        "    fixed_detected = pair[\"fixed\"][\"detected_cwes\"]\n",
        "\n",
        "    is_vuln_tp = gt_cwe in vuln_detected\n",
        "    is_vuln_fn = not is_vuln_tp\n",
        "    is_fixed_fp = gt_cwe in fixed_detected\n",
        "    is_fixed_tn = not is_fixed_fp\n",
        "\n",
        "    vuln_sem_score = 0.0\n",
        "    if is_vuln_fn and vuln_detected:\n",
        "        gt_emb = cwe_embeddings.get(gt_cwe)\n",
        "        scores = [util.cos_sim(gt_emb, cwe_embeddings.get(det)).item()\n",
        "                  for det in vuln_detected if cwe_embeddings.get(det) is not None]\n",
        "        if scores:\n",
        "            vuln_sem_score = max(scores)\n",
        "\n",
        "    fixed_sem_score = 0.0\n",
        "    if is_fixed_fp and fixed_detected:\n",
        "        gt_emb = cwe_embeddings.get(gt_cwe)\n",
        "        scores = [util.cos_sim(gt_emb, cwe_embeddings.get(det)).item()\n",
        "                  for det in fixed_detected if cwe_embeddings.get(det) is not None]\n",
        "        if scores:\n",
        "            fixed_sem_score = max(scores)\n",
        "\n",
        "    return {\n",
        "        \"pair_id\": pair[\"pair_id\"],\n",
        "        \"is_vuln_tp\": is_vuln_tp,\n",
        "        \"is_vuln_fn\": is_vuln_fn,\n",
        "        \"vuln_semantic_score\": vuln_sem_score,\n",
        "        \"is_fixed_tn\": is_fixed_tn,\n",
        "        \"is_fixed_fp\": is_fixed_fp,\n",
        "        \"fixed_semantic_score\": fixed_sem_score\n",
        "    }\n",
        "\n",
        "semantic_results = [compute_semantic_fn_tp(pair, cwe_embeddings) for pair in data[\"pairs\"]]\n",
        "\n",
        "for r in semantic_results[:5]:\n",
        "    print(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYl8dn4fSoG6"
      },
      "outputs": [],
      "source": [
        "semantic_recall = np.mean([r[\"vuln_semantic_score\"] for r in semantic_results])\n",
        "print(f\"Semantic recall approx.: {semantic_recall:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7TSe0kvSwJT"
      },
      "outputs": [],
      "source": [
        "vuln_scores = [r[\"vuln_semantic_score\"] for r in semantic_results if r[\"is_vuln_fn\"]]\n",
        "fixed_scores = [r[\"fixed_semantic_score\"] for r in semantic_results if r[\"is_fixed_fp\"]]\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(vuln_scores, bins=20, color='tomato', alpha=0.7)\n",
        "plt.title(\"Vulnerable FN — Semantic Similarity Scores\")\n",
        "plt.xlabel(\"Max Semantic Score with GT CWE\")\n",
        "plt.ylabel(\"Count\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist(fixed_scores, bins=20, color='skyblue', alpha=0.7)\n",
        "plt.title(\"Fixed FP — Semantic Similarity Scores\")\n",
        "plt.xlabel(\"Max Semantic Score with GT CWE\")\n",
        "plt.ylabel(\"Count\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Vulnerable FN count: {len(vuln_scores)}, mean score: {np.mean(vuln_scores):.3f}\")\n",
        "print(f\"Fixed FP count: {len(fixed_scores)}, mean score: {np.mean(fixed_scores):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGQOuC3pTg-9"
      },
      "outputs": [],
      "source": [
        "def calculate_prediction_metrics(data):\n",
        "\n",
        "    tp = tn = fp = fn = 0\n",
        "    pairs_correct = 0\n",
        "    pairs_reversed = 0\n",
        "\n",
        "    for pair in data[\"pairs\"]:\n",
        "        vuln_pred = pair[\"vulnerable\"][\"prediction\"]\n",
        "        vuln_correct = pair[\"vulnerable\"][\"correct\"]\n",
        "\n",
        "        fixed_pred = pair[\"fixed\"][\"prediction\"]\n",
        "        fixed_correct = pair[\"fixed\"][\"correct\"]\n",
        "\n",
        "        if vuln_pred and vuln_correct:\n",
        "            tp += 1\n",
        "            vuln_fn = False\n",
        "        else:\n",
        "            vuln_fn = True\n",
        "            fn += 1\n",
        "\n",
        "        if not fixed_pred and fixed_correct:\n",
        "            tn += 1\n",
        "            fixed_fp = False\n",
        "        else:\n",
        "            fixed_fp = True\n",
        "            fp += 1\n",
        "\n",
        "        if not vuln_fn and not fixed_fp:\n",
        "            pairs_correct += 1\n",
        "        elif vuln_fn and fixed_fp:\n",
        "            pairs_reversed += 1\n",
        "\n",
        "    total = tp + tn + fp + fn\n",
        "    accuracy = (tp + tn) / total if total > 0 else 0\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    vps = pairs_correct - pairs_reversed\n",
        "\n",
        "    return {\n",
        "        \"TP\": tp, \"TN\": tn, \"FP\": fp, \"FN\": fn, \"Total\": total,\n",
        "        \"P-C (Pairs Correct)\": pairs_correct,\n",
        "        \"P-R (Pairs Reversed)\": pairs_reversed,\n",
        "        \"VPS\": vps,\n",
        "        \"Accuracy\": round(accuracy,4),\n",
        "        \"Precision\": round(precision,4),\n",
        "        \"Recall\": round(recall,4),\n",
        "        \"F1-Score\": round(f1_score,4)\n",
        "    }\n",
        "\n",
        "prediction_metrics = calculate_prediction_metrics(data)\n",
        "print(\"=== Metrics based on predictions ===\")\n",
        "for k,v in prediction_metrics.items():\n",
        "    print(f\"{k}: {v}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAomg5zGT2eh"
      },
      "outputs": [],
      "source": [
        "vuln_fn_results = [r for r in semantic_results if r.get(\"is_vuln_fn\", False)]\n",
        "vuln_fn_count = len(vuln_fn_results)\n",
        "vuln_fn_scores = []\n",
        "for r in vuln_fn_results:\n",
        "    scores = r.get(\"vulnerable_semantic_scores\", [])\n",
        "    if scores:\n",
        "        vuln_fn_scores.append(max(s[\"semantic_score\"] for s in scores))\n",
        "    else:\n",
        "        vuln_fn_scores.append(0)\n",
        "vuln_fn_mean_score = np.mean(vuln_fn_scores) if vuln_fn_scores else 0\n",
        "\n",
        "fixed_fp_results = [r for r in semantic_results if r.get(\"is_fixed_fn\", False) or r.get(\"is_fixed_fp\", False)]\n",
        "fixed_fp_count = len(fixed_fp_results)\n",
        "fixed_fp_scores = []\n",
        "for r in fixed_fp_results:\n",
        "    scores = r.get(\"fixed_semantic_scores\", [])\n",
        "    if scores:\n",
        "        fixed_fp_scores.append(max(s[\"semantic_score\"] for s in scores))\n",
        "    else:\n",
        "        fixed_fp_scores.append(0)\n",
        "fixed_fp_mean_score = np.mean(fixed_fp_scores) if fixed_fp_scores else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqYCX5HPWbtZ"
      },
      "outputs": [],
      "source": [
        "def plot_confusion(metrics, save_path=None):\n",
        "    cm = np.array([[metrics['TP'], metrics['FN']],\n",
        "                   [metrics['FP'], metrics['TN']]])\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Predicted Vulnerable', 'Predicted Safe'],\n",
        "                yticklabels=['Actually Vulnerable', 'Actually Safe'])\n",
        "    plt.title(\"Confusion Matrix\", fontsize=14)\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion(prediction_metrics, save_path=\"confusion_matrix.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJvAWPrAWlLG"
      },
      "outputs": [],
      "source": [
        "metrics_summary = pd.DataFrame({\n",
        "    'Metric': ['Precision', 'Recall', 'F1-Score'],\n",
        "    'Value': [metrics['Precision'], metrics['Recall'], metrics['F1-Score']]\n",
        "})\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(x='Metric', y='Value', data=metrics_summary, palette='coolwarm')\n",
        "plt.ylim(0,1)\n",
        "plt.title(\"Key Performance Metrics\")\n",
        "for i, v in enumerate(metrics_summary['Value']):\n",
        "    plt.text(i, v + 0.02, f\"{v:.2%}\", ha='center', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"performance_metrics.png\", dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP1aCYbfZlRG"
      },
      "outputs": [],
      "source": [
        "metrics = [\"PC\", \"PR\", \"VPS\", \"FPR\", \"F1-score\", \"ACC\"]\n",
        "\n",
        "# VulAgent baseline (paper)\n",
        "vulagent = [17.7, 8.74, 8.96, 19.95, 41.59, 54.73]\n",
        "\n",
        "# VulTrial baseline\n",
        "vultrial = [18.6, 11.4, 7.13, 52.6, 56.1, 53.4]\n",
        "\n",
        "# VulPrune\n",
        "vulprune = [\n",
        "    5.0,   # PC (%)\n",
        "    0.0,   # PR (%)\n",
        "    5.0,   # VPS (%)\n",
        "    90.0,   # FPR (%)\n",
        "    68.97, # F1-score (%)\n",
        "    55.0   # Accuracy (%)\n",
        "]\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"Metric\": metrics,\n",
        "    \"VulAgent\": vulagent,\n",
        "    \"VulPrune\": vulprune,\n",
        "    \"VulTrial\": vultrial\n",
        "})\n",
        "\n",
        "arrows = []\n",
        "for i, row in df.iterrows():\n",
        "    if row[\"Metric\"] in [\"FPR\", \"PR\"]:\n",
        "        arrows.append('↑' if row[\"VulPrune\"] < row[\"VulAgent\"] else '↓')\n",
        "    else:\n",
        "        arrows.append('↑' if row[\"VulPrune\"] > row[\"VulAgent\"] else '↓')\n",
        "\n",
        "colors = ['green' if a == '↑' else 'red' for a in arrows]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "ax.axis('tight')\n",
        "ax.axis('off')\n",
        "\n",
        "table_data = []\n",
        "for i, row in df.iterrows():\n",
        "    table_data.append([\n",
        "        row[\"Metric\"],\n",
        "        f\"{row['VulAgent']:.2f}\",\n",
        "        f\"{row['VulPrune']:.2f} {arrows[i]}\",\n",
        "        f\"{row['VulTrial']:.2f}\"\n",
        "    ])\n",
        "\n",
        "table = ax.table(\n",
        "    cellText=table_data,\n",
        "    colLabels=[\"Metric\", \"VulAgent\", \"VulPrune\", \"VulTrial\"],\n",
        "    cellLoc='center',\n",
        "    loc='center'\n",
        ")\n",
        "\n",
        "for i, color in enumerate(colors):\n",
        "    table[i+1, 2].set_text_props(color=color, weight='bold')\n",
        "\n",
        "plt.title(\"Metrics Comparison with Arrows (↑ better, ↓ worse)\", fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SxxrSC4oIy8"
      },
      "outputs": [],
      "source": [
        "pairs = data[\"pairs\"]\n",
        "gt_list = [p[\"ground_truth_cwe\"] for p in pairs]\n",
        "\n",
        "dist = pd.DataFrame(Counter(gt_list).most_common(), columns=[\"vulnerability\", \"count\"])\n",
        "display(dist)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "colors = plt.cm.tab20(np.linspace(0, 1, len(dist)))\n",
        "\n",
        "bars = plt.bar(dist[\"vulnerability\"], dist[\"count\"], color=colors)\n",
        "\n",
        "for bar in bars:\n",
        "    h = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, h, str(int(h)), ha=\"center\", va=\"bottom\")\n",
        "\n",
        "plt.xlabel(\"vulnerability\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.title(\"Distribution of unique ground-truth vulnerabilities\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABLwP-t4qiQI"
      },
      "outputs": [],
      "source": [
        "pairs = data[\"pairs\"]\n",
        "detected = []\n",
        "\n",
        "for p in pairs:\n",
        "    vuln = p.get(\"vulnerable\", {}).get(\"detected_cwes\", [])\n",
        "    fixed = p.get(\"fixed\", {}).get(\"detected_cwes\", [])\n",
        "    detected.extend(vuln)\n",
        "    detected.extend(fixed)\n",
        "\n",
        "dist_det = pd.DataFrame(Counter(detected).most_common(), columns=[\"vulnerability\", \"count\"])\n",
        "display(dist_det)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "colors = plt.cm.tab20(np.linspace(0, 1, len(dist_det)))\n",
        "bars = plt.bar(dist_det[\"vulnerability\"], dist_det[\"count\"], color=colors)\n",
        "\n",
        "for bar in bars:\n",
        "    h = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, h, str(int(h)), ha=\"center\", va=\"bottom\")\n",
        "\n",
        "plt.xlabel(\"vulnerability\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.title(\"Distribution of detected CWE\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
