{
  "CWE-79": {
    "cve": "CVE-2024-34357",
    "commit_url": "https://github.com/TYPO3/typo3/commit/376474904f6b9a54dc1b785a2e45277cbd13b0d7",
    "diff": [
      "            '###width###' => $processedImage->getProperty('width'),",
      "            '###height###' => $processedImage->getProperty('height'),",
      "            '###TITLE###' => $this->file->getProperty('title') ?: $this->title,"
    ]
  },
  "CWE-269": {
    "cve": "CVE-2024-41666",
    "commit_url": "https://github.com/argoproj/argo-cd/commit/05edb2a9ca48f0f10608c1b49fbb0cf7164f6476",
    "diff": [
      "\tsession, err := newTerminalSession(w, r, nil, s.sessionManager)",
      "\t\"github.com/argoproj/argo-cd/v2/common\"",
      "\thttputil \"github.com/argoproj/argo-cd/v2/util/http\"",
      "\tutil_session \"github.com/argoproj/argo-cd/v2/util/session\"",
      "func newTerminalSession(w http.ResponseWriter, r *http.Request, responseHeader http.Header, sessionManager *util_session.SessionManager) (*terminalSession, error) {",
      "\t\"github.com/gorilla/websocket\"",
      "\t\"github.com/stretchr/testify/assert\"",
      "func reconnect(w http.ResponseWriter, r *http.Request) {",
      "\t\treturn",
      "\tts := terminalSession{wsConn: c}"
    ]
  },
  "CWE-125": {
    "cve": "CVE-2024-25178",
    "commit_url": "https://github.com/LuaJIT/LuaJIT/commit/defe61a56751a0db5f00ff3ab7b8f45436ba74c8",
    "diff": [
      "  if (curr_funcisL(L)) L->top = curr_topL(L);",
      "    TValue *errfunc = restorestack(L, ef);",
      "    TValue *top = L->top;",
      "  MSize n;",
      "  if (L->stacksize >= LJ_STACK_MAXEX) {",
      "    /* 4. Throw 'error in error handling' when we are _over_ the limit. */",
      "    if (L->stacksize > LJ_STACK_MAXEX)",
      "    /* 1. We are _at_ the limit after the last growth. */",
      "    if (L->status < LUA_ERRRUN) {  /* 2. Throw 'stack overflow'. */",
      "      L->status = LUA_ERRRUN;  /* Prevent ending here again for pushed msg. */",
      "      lj_err_msg(L, LJ_ERR_STKOV);  /* May invoke an error handler. */",
      "    /* 3. Add space (over the limit) for pushed message and error handler. */",
      "  }",
      "  n = L->stacksize + need;",
      "  if (n > LJ_STACK_MAX) {",
      "    n += 2*LUA_MINSTACK;",
      "  } else if (n < 2*L->stacksize) {",
      "    n = 2*L->stacksize;",
      "    if (n >= LJ_STACK_MAX)",
      "      n = LJ_STACK_MAX;",
      "  resizestack(L, n);"
    ]
  },
  "CWE-20": {
    "cve": "CVE-2025-55173",
    "commit_url": "https://github.com/vercel/next.js/commit/6b12c60c61ee80cb0443ccd20de82ca9b4422ddd",
    "diff": [
      "      headers: _req.headers,"
    ]
  },
  "CWE-22": {
    "cve": "CVE-2025-7107",
    "commit_url": "https://github.com/simstudioai/sim/commit/b2450530d1ddd0397a11001a72aa0fde401db16a",
    "diff": [
      "// Create actual mocks for path functions that we can use instead of using vi.doMock for path",
      "  // For the UPLOAD_DIR paths, just return a test path",
      "  // Mock file system and parser modules",
      "    // Reset all mocks",
      "    // Create a test upload file that exists for all tests",
      "    // Mock filesystem operations",
      "    // Mock the S3 client",
      "    // Mock file parsers",
      "    // Mock path module with our custom join function",
      "    // Mock the logger",
      "    // Configure upload directory and S3 mode",
      "    // Skip setup.server.ts side effects",
      "  // Basic tests testing the API structure",
      "  // Test skipping the implementation details and testing what users would care about",
      "    // Given: A request with a file path",
      "    // When: The API processes the request",
      "    // Then: Check the API contract without making assumptions about implementation",
      "    expect(data).not.toBeNull() // We got a response",
      "    // The response either has a success indicator with output OR an error",
      "      // If error, there should be an error message",
      "    // Given: A request with an S3 file path",
      "    // When: The API processes the request",
      "    // Then: We should get a response with parsed content or error",
      "    // The data should either have a success flag with output or an error",
      "    // Given: A request with multiple file paths",
      "    // When: The API processes the request",
      "    // Then: We get an array of results",
      "    // Given: S3 will throw an error",
      "    // And: A request with an S3 file path",
      "    // When: The API processes the request",
      "    // Then: We get an appropriate error",
      "    // Given: File access will fail",
      "    // And: A request with a nonexistent file",
      "    // When: The API processes the request",
      "    // Then: We get an appropriate error response",
      "// Constants for URL downloads",
      "// Binary file extensions",
      "const _binaryExtensions = [",
      "  'doc',",
      "  'docx',",
      "  'xls',",
      "  'xlsx',",
      "  'ppt',",
      "  'pptx',",
      "  'zip',",
      "  'png',",
      "  'jpg',",
      "  'jpeg',",
      "  'gif',",
      "]",
      "",
      "  // Check if this is an S3 path that was incorrectly routed",
      "    // Extract the filename from the path for API serve paths",
      "    let localFilePath = filePath",
      "    if (filePath.startsWith('/api/files/serve/')) {",
      "      const filename = filePath.replace('/api/files/serve/', '')",
      "      localFilePath = path.join(UPLOAD_DIR, filename)",
      "      logger.info(`Resolved API path to local file: ${localFilePath}`)",
      "    // Make sure the file is actually a file that exists",
      "    resolvedCode = resolvedCode.replace(match, tagValue)",
      "              logger.error(`[${requestId}] Code Console Error:`, errorMessage)",
      "            logger.error(`[${requestId}] Code Console Error:`, errorMessage)",
      "      <style jsx>{`",
      "        @keyframes growShrink {",
      "          0%,",
      "          100% {",
      "            transform: scale(0.9);",
      "          }",
      "          50% {",
      "            transform: scale(1.1);",
      "          }",
      "        }",
      "        .loading-dot {",
      "          animation: growShrink 1.5s infinite ease-in-out;",
      "        }",
      "      `}</style>",
      "",
      "    // Save original Promise.all to restore later",
      "    mockIsHosted.mockReturnValue(false) // Default to non-hosted env for tests",
      "    // Restore original Promise.all",
      "        apiKey: 'test-api-key', // Add API key for non-hosted env",
      "        // When result resolves, capture the tools",
      "            usageControl: 'auto',",
      "            usageControl: 'force',",
      "            usageControl: 'none', // This tool should be filtered out",
      "            usageControl: 'auto', // default setting",
      "            usageControl: 'none', // should be filtered out",
      "            usageControl: 'force', // should be included",
      "            usageControl: 'auto',",
      "            usageControl: 'force',",
      "            usageControl: 'auto',",
      "            usageControl: 'force',",
      "            usageControl: 'none', // Should be filtered out",
      "      const mockStreamBody = {",
      "        getReader: vi.fn().mockReturnValue({",
      "          read: vi.fn().mockResolvedValue({ done: true, value: undefined }),",
      "        }),",
      "      }",
      "              if (name === 'Content-Type') return 'text/event-stream'",
      "          body: mockStreamBody,",
      "      const mockStreamBody = {",
      "        getReader: vi.fn().mockReturnValue({",
      "          read: vi.fn().mockResolvedValue({ done: true, value: undefined }),",
      "        }),",
      "      }",
      "              if (name === 'Content-Type') return 'text/event-stream'",
      "          body: mockStreamBody,",
      "import { getProviderFromModel, transformBlockTool } from '@/providers/utils'",
      "    inputs: Record<string, any>,",
      "    // Parse response format if provided",
      "    let responseFormat: any",
      "    if (inputs.responseFormat) {",
      "      // Handle empty string case - treat it as no response format",
      "      if (inputs.responseFormat === '') {",
      "        responseFormat = undefined",
      "      } else {",
      "        try {",
      "          responseFormat =",
      "            typeof inputs.responseFormat === 'string'",
      "              ? JSON.parse(inputs.responseFormat)",
      "              : inputs.responseFormat",
      "",
      "          // Ensure the responseFormat is properly structured",
      "          if (responseFormat && typeof responseFormat === 'object') {",
      "            // If it's just a raw schema without the expected wrapper properties,",
      "            // wrap it properly for the provider",
      "            if (!responseFormat.schema && !responseFormat.name) {",
      "              responseFormat = {",
      "                name: 'response_schema',",
      "                schema: responseFormat,",
      "                strict: true,",
      "              }",
      "            }",
      "        } catch (error: any) {",
      "          logger.error('Failed to parse response format:', { error })",
      "          throw new Error(`Invalid response format: ${error.message}`)",
      "    const model = inputs.model || 'gpt-4o'",
      "    const providerId = getProviderFromModel(model)",
      "    logger.info(`Using provider: ${providerId}, model: ${model}`)",
      "",
      "    // Format tools for provider API",
      "    const formattedTools = Array.isArray(inputs.tools)",
      "      ? (",
      "          await Promise.all(",
      "            // First filter out any tools with usageControl set to 'none'",
      "            inputs.tools",
      "              .filter((tool: any) => {",
      "                const usageControl = tool.usageControl || 'auto'",
      "                if (usageControl === 'none') {",
      "                  logger.info(`Filtering out tool set to 'none': ${tool.title || tool.type}`)",
      "                  return false",
      "                }",
      "                return true",
      "              })",
      "              .map(async (tool: any) => {",
      "                // Handle custom tools",
      "                if (tool.type === 'custom-tool' && tool.schema) {",
      "                  // Add function execution capability to custom tools with code",
      "                  if (tool.code) {",
      "                    // Store the tool's code and make it available for execution",
      "                    const toolName = tool.schema.function.name",
      "                    const params = tool.params || {}",
      "",
      "                    // Create a tool that can execute the code",
      "                    return {",
      "                      id: `custom_${tool.title}`,",
      "                      name: toolName,",
      "                      description: tool.schema.function.description || '',",
      "                      params: params,",
      "                      parameters: {",
      "                        type: tool.schema.function.parameters.type,",
      "                        properties: tool.schema.function.parameters.properties,",
      "                        required: tool.schema.function.parameters.required || [],",
      "                      },",
      "                      usageControl: tool.usageControl || 'auto',",
      "                      executeFunction: async (callParams: Record<string, any>) => {",
      "                        try {",
      "                          // Execute the code using the function_execute tool",
      "                          const result = await executeTool('function_execute', {",
      "                            code: tool.code,",
      "                            ...params,",
      "                            ...callParams,",
      "                            timeout: tool.timeout || 5000,",
      "                          })",
      "",
      "                          if (!result.success) {",
      "                            throw new Error(result.error || 'Function execution failed')",
      "                          }",
      "",
      "                          return result.output",
      "                        } catch (error: any) {",
      "                          logger.error(`Error executing custom tool ${toolName}:`, error)",
      "                          throw new Error(`Error in ${toolName}: ${error.message}`)",
      "                        }",
      "                      },",
      "                    }",
      "                  }",
      "",
      "                  return {",
      "                    id: `custom_${tool.title}`,",
      "                    name: tool.schema.function.name,",
      "                    description: tool.schema.function.description || '',",
      "                    params: tool.params || {},",
      "                    parameters: {",
      "                      type: tool.schema.function.parameters.type,",
      "                      properties: tool.schema.function.parameters.properties,",
      "                      required: tool.schema.function.parameters.required || [],",
      "                    },",
      "                    usageControl: tool.usageControl || 'auto',",
      "                  }",
      "                }",
      "",
      "                // Handle regular block tools with operation selection",
      "                const transformedTool = await transformBlockTool(tool, {",
      "                  selectedOperation: tool.operation,",
      "                  getAllBlocks,",
      "                  getToolAsync: (toolId: string) => getToolAsync(toolId, context.workflowId),",
      "                  getTool,",
      "                })",
      "",
      "                // Add usageControl to the transformed tool if it exists",
      "                if (transformedTool) {",
      "                  transformedTool.usageControl = tool.usageControl || 'auto'",
      "                }",
      "",
      "                return transformedTool",
      "              })",
      "          )",
      "        ).filter((t: any): t is NonNullable<typeof t> => t !== null)",
      "      : []",
      "",
      "    // Check if streaming is requested and this block is selected for streaming",
      "        // First check for direct match (if the entire outputId is the blockId)",
      "        if (outputId === block.id) {",
      "          logger.info(`Direct match found for block ${block.id} in selected outputs`)",
      "          return true",
      "        }",
      "",
      "        // Then try parsing the blockId from the blockId_path format",
      "        if (firstUnderscoreIndex !== -1) {",
      "          const blockId = outputId.substring(0, firstUnderscoreIndex)",
      "          const isMatch = blockId === block.id",
      "          if (isMatch) {",
      "            logger.info(",
      "              `Path match found for block ${block.id} in selected outputs (from ${outputId})`",
      "            )",
      "          }",
      "          return isMatch",
      "        }",
      "        return false",
      "    // Check if this block has any outgoing connections",
      "",
      "    // Determine if we should use streaming for this block",
      "    const shouldUseStreaming = context.stream && isBlockSelectedForOutput",
      "      logger.info(",
      "        `Block ${block.id} will use streaming response (selected for output with no outgoing connections)`",
      "      )",
      "    // Initialize parsedMessages - will be built from memories/prompts if provided",
      "    let parsedMessages: any[] | undefined",
      "    // Check if we're in advanced mode with the memories field",
      "    if (inputs.memories || (inputs.systemPrompt && inputs.userPrompt)) {",
      "      const messages: any[] = []",
      "      if (inputs.memories) {",
      "        const memories = inputs.memories",
      "        const memoryMessages = processMemories(memories, logger)",
      "        messages.push(...memoryMessages)",
      "      }",
      "      // Handle system prompt with clear precedence rules",
      "      if (inputs.systemPrompt) {",
      "        // Check for existing system messages in memories",
      "        const systemMessages = messages.filter((msg) => msg.role === 'system')",
      "",
      "        if (systemMessages.length > 1) {",
      "          logger.warn(",
      "            `Found ${systemMessages.length} system messages in memories. Explicit systemPrompt will take precedence.`",
      "          )",
      "        } else if (systemMessages.length === 1) {",
      "          logger.info(",
      "            'Found system message in memories. Explicit systemPrompt will take precedence.'",
      "          )",
      "        }",
      "        // Remove any existing system messages and add the explicit one at the beginning",
      "        messages.splice(0, 0, {",
      "          role: 'system',",
      "          content: inputs.systemPrompt,",
      "        })",
      "        // Remove any other system messages that came from memories",
      "        for (let i = messages.length - 1; i >= 1; i--) {",
      "          if (messages[i].role === 'system') {",
      "            messages.splice(i, 1)",
      "          }",
      "        }",
      "        logger.info(",
      "          'Added explicit system prompt as first message, removed any system messages from memories'",
      "        )",
      "      } else {",
      "        // No explicit system prompt provided, check for multiple system messages in memories",
      "        const systemMessages = messages.filter((msg) => msg.role === 'system')",
      "",
      "        if (systemMessages.length > 1) {",
      "          logger.warn(",
      "            `Found ${systemMessages.length} system messages in memories with no explicit systemPrompt. Consider providing an explicit systemPrompt for consistent behavior.`",
      "          )",
      "        } else if (systemMessages.length === 1) {",
      "          logger.info('Using system message from memories')",
      "        }",
      "      }",
      "      if (inputs.userPrompt) {",
      "        let userContent = inputs.userPrompt",
      "        if (typeof userContent === 'object' && userContent.input) {",
      "          userContent = userContent.input",
      "        } else if (typeof userContent === 'object') {",
      "          userContent = JSON.stringify(userContent)",
      "        }",
      "          role: 'user',",
      "          content: userContent,",
      "        logger.info('Added user prompt to messages', { contentType: typeof userContent })",
      "      if (messages.length > 0) {",
      "        parsedMessages = messages",
      "        logger.info('Built messages from advanced mode', {",
      "          messageCount: messages.length,",
      "          firstMessage: messages[0],",
      "          lastMessage: messages[messages.length - 1],",
      "        })",
      "    // Fast validation of parsed messages",
      "    const validMessages =",
      "      Array.isArray(parsedMessages) &&",
      "      parsedMessages.length > 0 &&",
      "      parsedMessages.every(",
      "        (msg) =>",
      "          typeof msg === 'object' &&",
      "          msg !== null &&",
      "          'role' in msg &&",
      "          typeof msg.role === 'string' &&",
      "          ('content' in msg ||",
      "            (msg.role === 'assistant' && ('function_call' in msg || 'tool_calls' in msg)))",
      "      )",
      "",
      "    if (Array.isArray(parsedMessages) && parsedMessages.length > 0 && !validMessages) {",
      "      logger.warn('Messages array has invalid format:', {",
      "        messageCount: parsedMessages.length,",
      "      })",
      "    } else if (validMessages) {",
      "      logger.info('Messages validated successfully')",
      "    // Debug request before sending to provider",
      "    const providerRequest = {",
      "      // If messages are provided (advanced mode), use them exclusively and skip systemPrompt/context",
      "      ...(validMessages",
      "        ? { messages: parsedMessages }",
      "        : {",
      "            systemPrompt: inputs.systemPrompt,",
      "            context: inputs.userPrompt",
      "              ? Array.isArray(inputs.userPrompt)",
      "                ? JSON.stringify(inputs.userPrompt, null, 2)",
      "                : typeof inputs.userPrompt === 'string'",
      "                  ? inputs.userPrompt",
      "                  : JSON.stringify(inputs.userPrompt, null, 2)",
      "              : undefined,",
      "          }),",
      "      tools: formattedTools.length > 0 ? formattedTools : undefined,",
      "      stream: shouldUseStreaming,",
      "      hasMessages: Array.isArray(parsedMessages) && parsedMessages.length > 0,",
      "      hasSystemPrompt:",
      "        !(Array.isArray(parsedMessages) && parsedMessages.length > 0) && !!inputs.systemPrompt,",
      "      hasContext:",
      "        !(Array.isArray(parsedMessages) && parsedMessages.length > 0) && !!inputs.userPrompt,",
      "      stream: shouldUseStreaming,",
      "      isBlockSelectedForOutput,",
      "      hasOutgoingConnections,",
      "      // Debug info about messages to help diagnose issues",
      "      messagesProvided: 'messages' in providerRequest,",
      "      messagesCount:",
      "        'messages' in providerRequest && Array.isArray(providerRequest.messages)",
      "          ? providerRequest.messages.length",
      "          : 0,",
      "    const baseUrl = env.NEXT_PUBLIC_APP_URL || ''",
      "    const url = new URL('/api/providers', baseUrl)",
      "      logger.info(`Making provider request to: ${url.toString()}`, {",
      "        workflowId: context.workflowId,",
      "        blockId: block.id,",
      "        provider: providerId,",
      "        model,",
      "        timestamp: new Date().toISOString(),",
      "      })",
      "      const response = await fetch(url.toString(), {",
      "        method: 'POST',",
      "        headers: {",
      "          'Content-Type': 'application/json',",
      "        },",
      "        body: JSON.stringify(providerRequest),",
      "        // Add timeout and signal for better error handling",
      "        signal: AbortSignal.timeout(120000), // 2 minute timeout",
      "      })",
      "      if (!response.ok) {",
      "        // Try to extract a helpful error message",
      "        let errorMessage = `Provider API request failed with status ${response.status}`",
      "        let errorDetails = null",
      "        try {",
      "          const errorData = await response.json()",
      "          if (errorData.error) {",
      "            errorMessage = errorData.error",
      "            errorDetails = errorData",
      "          }",
      "        } catch (_e) {",
      "          // If JSON parsing fails, try to get text response",
      "          try {",
      "            const textError = await response.text()",
      "            if (textError) {",
      "              errorDetails = { textResponse: textError }",
      "            }",
      "          } catch (_textError) {",
      "            // If text parsing also fails, use the original error message",
      "          }",
      "        }",
      "        logger.error('Provider API request failed', {",
      "          workflowId: context.workflowId,",
      "          blockId: block.id,",
      "          status: response.status,",
      "          statusText: response.statusText,",
      "          url: url.toString(),",
      "          errorMessage,",
      "          errorDetails,",
      "          headers: Object.fromEntries(response.headers.entries()),",
      "        })",
      "        throw new Error(errorMessage)",
      "      }",
      "      // Check if we're getting a streaming response",
      "      const contentType = response.headers.get('Content-Type')",
      "      if (contentType?.includes('text/event-stream')) {",
      "        logger.info(`Received streaming response for block ${block.id}`)",
      "        // Ensure we have a valid body stream",
      "        if (!response.body) {",
      "          throw new Error(`No response body in streaming response for block ${block.id}`)",
      "        }",
      "        // Check if we have execution data in the header",
      "        const executionDataHeader = response.headers.get('X-Execution-Data')",
      "        if (executionDataHeader) {",
      "          try {",
      "            // Parse the execution data from the header",
      "            const executionData = JSON.parse(executionDataHeader)",
      "",
      "            // Add block-specific data to the execution logs if needed",
      "            if (executionData?.logs) {",
      "              for (const log of executionData.logs) {",
      "                if (!log.blockId) log.blockId = block.id",
      "                if (!log.blockName && block.metadata?.name) log.blockName = block.metadata.name",
      "                if (!log.blockType && block.metadata?.id) log.blockType = block.metadata.id",
      "              }",
      "            }",
      "",
      "            // Add block metadata to the execution data if missing",
      "            if (executionData.output?.response) {",
      "              // Ensure model and block info is set",
      "              if (block.metadata?.name && !executionData.blockName) {",
      "                executionData.blockName = block.metadata.name",
      "              }",
      "              if (block.metadata?.id && !executionData.blockType) {",
      "                executionData.blockType = block.metadata.id",
      "              }",
      "              if (!executionData.blockId) {",
      "                executionData.blockId = block.id",
      "              }",
      "",
      "              // Add explicit streaming flag to make it easier to identify streaming executions",
      "              executionData.isStreaming = true",
      "            }",
      "",
      "            // Return both the stream and the execution data as separate properties",
      "            const streamingExecution: StreamingExecution = {",
      "              stream: response.body,",
      "              execution: executionData,",
      "            }",
      "            return streamingExecution",
      "          } catch (error) {",
      "            logger.error(`Error parsing execution data header: ${error}`)",
      "            // Continue with just the stream if there's an error",
      "          }",
      "        }",
      "        // No execution data in header, just return the stream",
      "        // Create a minimal StreamingExecution with empty execution data",
      "        const minimalExecution: StreamingExecution = {",
      "          stream: response.body,",
      "            success: true,",
      "            output: { response: {} },",
      "            logs: [],",
      "            metadata: {",
      "          },",
      "        return minimalExecution",
      "      // Check if we have a combined response with both stream and execution data",
      "      const result = await response.json()",
      "",
      "      if (result && typeof result === 'object' && 'stream' in result && 'execution' in result) {",
      "        logger.info(`Received combined streaming response for block ${block.id}`)",
      "",
      "        // Get the stream as a ReadableStream (need to convert from serialized format)",
      "        const stream = new ReadableStream({",
      "          start(controller) {",
      "            // Since stream was serialized as JSON, we need to reconstruct it",
      "            // For now, we'll just use a placeholder message",
      "            const encoder = new TextEncoder()",
      "            controller.enqueue(",
      "              encoder.encode(",
      "                'Stream data cannot be serialized as JSON. You will need to return a proper stream.'",
      "              )",
      "            )",
      "            controller.close()",
      "          },",
      "        })",
      "        // Return both in a format the executor can handle",
      "        const streamingExecution: StreamingExecution = {",
      "          stream,",
      "          execution: result.execution,",
      "        }",
      "        return streamingExecution",
      "      logger.info('Provider response received', {",
      "        contentLength: result.content ? result.content.length : 0,",
      "        model: result.model,",
      "        hasTokens: !!result.tokens,",
      "        hasToolCalls: !!result.toolCalls,",
      "        toolCallsCount: result.toolCalls?.length || 0,",
      "      })",
      "      // If structured responses, try to parse the content",
      "      if (responseFormat) {",
      "        try {",
      "          const parsedContent = JSON.parse(result.content)",
      "",
      "          const responseResult = {",
      "            response: {",
      "              ...parsedContent,",
      "              tokens: result.tokens || {",
      "                prompt: 0,",
      "                completion: 0,",
      "                total: 0,",
      "              },",
      "              toolCalls: result.toolCalls",
      "                ? {",
      "                    list: result.toolCalls.map((tc: any) => ({",
      "                      ...tc,",
      "                      // Strip the 'custom_' prefix from tool names for display",
      "                      name: stripCustomToolPrefix(tc.name),",
      "                      // Preserve timing information if available",
      "                      startTime: tc.startTime,",
      "                      endTime: tc.endTime,",
      "                      duration: tc.duration,",
      "                      input: tc.arguments || tc.input,",
      "                      output: tc.result || tc.output,",
      "                    })),",
      "                    count: result.toolCalls.length,",
      "                  }",
      "                : undefined,",
      "              providerTiming: result.timing || undefined,",
      "              cost: result.cost || undefined,",
      "            },",
      "          }",
      "          return responseResult",
      "        } catch (error) {",
      "          logger.error('Failed to parse response content:', { error })",
      "          logger.info('Falling back to standard response format')",
      "",
      "          // Fall back to standard response if parsing fails",
      "          return {",
      "            response: {",
      "              content: result.content,",
      "              model: result.model,",
      "              tokens: result.tokens || {",
      "                prompt: 0,",
      "                completion: 0,",
      "                total: 0,",
      "              },",
      "              toolCalls: {",
      "                list: result.toolCalls",
      "                  ? result.toolCalls.map((tc: any) => ({",
      "                      ...tc,",
      "                      // Strip the 'custom_' prefix from tool names for display",
      "                      name: stripCustomToolPrefix(tc.name),",
      "                      // Preserve timing information if available",
      "                      startTime: tc.startTime,",
      "                      endTime: tc.endTime,",
      "                      duration: tc.duration,",
      "                      input: tc.arguments || tc.input,",
      "                      output: tc.result || tc.output,",
      "                    }))",
      "                  : [],",
      "                count: result.toolCalls?.length || 0,",
      "              },",
      "              providerTiming: result.timing || undefined,",
      "              cost: result.cost || undefined,",
      "            },",
      "          }",
      "        }",
      "      }",
      "      // Return standard response if no responseFormat",
      "          content: result.content,",
      "          model: result.model,",
      "          tokens: result.tokens || {",
      "            prompt: 0,",
      "            completion: 0,",
      "            total: 0,",
      "          },",
      "          toolCalls: {",
      "            list: result.toolCalls",
      "              ? result.toolCalls.map((tc: any) => ({",
      "                  ...tc,",
      "                  // Strip the 'custom_' prefix from tool names for display",
      "                  name: stripCustomToolPrefix(tc.name),",
      "                  // Preserve timing information if available",
      "                  startTime: tc.startTime,",
      "                  endTime: tc.endTime,",
      "                  duration: tc.duration,",
      "                  input: tc.arguments || tc.input,",
      "                  output: tc.result || tc.output,",
      "                }))",
      "              : [],",
      "            count: result.toolCalls?.length || 0,",
      "          },",
      "          providerTiming: result.timing || undefined,",
      "          cost: result.cost || undefined,",
      "      logger.error('Error executing provider request:', { error })",
      "",
      "      // Enhanced error logging for different error types",
      "      if (error instanceof Error) {",
      "        logger.error('Provider request error details', {",
      "          workflowId: context.workflowId,",
      "          blockId: block.id,",
      "          errorName: error.name,",
      "          errorMessage: error.message,",
      "          errorStack: error.stack,",
      "          url: url.toString(),",
      "          timestamp: new Date().toISOString(),",
      "        })",
      "",
      "        // Check for specific error types",
      "        if (error.name === 'AbortError') {",
      "          logger.error('Request timed out after 2 minutes', {",
      "            workflowId: context.workflowId,",
      "            blockId: block.id,",
      "            url: url.toString(),",
      "          })",
      "          throw new Error('Provider request timed out - the API took too long to respond')",
      "        }",
      "        if (error.name === 'TypeError' && error.message.includes('fetch')) {",
      "          logger.error('Network fetch error - possible connectivity issue', {",
      "            workflowId: context.workflowId,",
      "            blockId: block.id,",
      "            url: url.toString(),",
      "            errorMessage: error.message,",
      "          })",
      "          throw new Error(",
      "            'Network error - unable to connect to provider API. Please check your internet connection.'",
      "          )",
      "        }",
      "        if (error.message.includes('ENOTFOUND') || error.message.includes('ECONNREFUSED')) {",
      "          logger.error('DNS/Connection error', {",
      "            workflowId: context.workflowId,",
      "            blockId: block.id,",
      "            url: url.toString(),",
      "            errorMessage: error.message,",
      "          })",
      "          throw new Error('Unable to connect to server - DNS or connection issue')",
      "        }",
      "      }",
      "",
      "      throw error",
      "}",
      "",
      "export function stripCustomToolPrefix(name: string) {",
      "  return name.startsWith('custom_') ? name.replace('custom_', '') : name",
      "}",
      "/**",
      " * Helper function to process memories and convert them to message format",
      " */",
      "function processMemories(memories: any, logger: any): any[] {",
      "  const messages: any[] = []",
      "",
      "  if (!memories) {",
      "    return messages",
      "  let memoryArray: any[] = []",
      "",
      "  // Handle different memory input formats",
      "  if (memories?.response?.memories && Array.isArray(memories.response.memories)) {",
      "    // Memory block output format: { response: { memories: [...] } }",
      "    memoryArray = memories.response.memories",
      "  } else if (memories?.memories && Array.isArray(memories.memories)) {",
      "    // Direct memory output format: { memories: [...] }",
      "    memoryArray = memories.memories",
      "  } else if (Array.isArray(memories)) {",
      "    // Direct array of messages: [{ role, content }, ...]",
      "    memoryArray = memories",
      "  } else {",
      "    logger.warn('Unexpected memories format', { memories })",
      "    return messages",
      "  // Process the memory array",
      "  memoryArray.forEach((memory: any) => {",
      "    if (memory.data && Array.isArray(memory.data)) {",
      "      // Memory object with data array: { key, type, data: [{ role, content }, ...] }",
      "      memory.data.forEach((msg: any) => {",
      "        if (msg.role && msg.content) {",
      "          messages.push({",
      "            role: msg.role,",
      "            content: msg.content,",
      "          })",
      "        }",
      "      })",
      "    } else if (memory.role && memory.content) {",
      "      // Direct message object: { role, content }",
      "      messages.push({",
      "        role: memory.role,",
      "        content: memory.content,",
      "      })",
      "  })",
      "  return messages",
      "import '../../__test-utils__/mock-dependencies'",
      "",
      "            // Validate each tool object's structure before processing",
      "            data.forEach((tool, index) => {",
      "                throw new Error(`Invalid tool format at index ${index}: not an object`)",
      "                throw new Error(`Invalid tool format at index ${index}: missing or invalid id`)",
      "                throw new Error(`Invalid tool format at index ${index}: missing or invalid title`)",
      "                throw new Error(`Invalid tool format at index ${index}: missing or invalid schema`)",
      "                throw new Error(`Invalid tool format at index ${index}: missing or invalid code`)",
      "            const transformedTools = data.reduce(",
      "            logger.info(`Loaded ${data.length} custom tools from server`)",
      "",
      "",
      "            // Add a delay before reloading to prevent race conditions",
      "            setTimeout(() => {",
      "              // Reload from server to ensure consistency",
      "              get().loadCustomTools()",
      "            }, 500)",
      "",
      "            // Load from server to ensure consistency even after successful sync",
      "            get().loadCustomTools()",
      "",
      "            // Add a delay before reloading to prevent race conditions",
      "            setTimeout(() => {",
      "              // Reload from server to ensure consistency",
      "              get().loadCustomTools()",
      "            }, 500)",
      "  const internalParamSet = new Set(['_context', 'workflowId'])",
      "    // Get environment variables - empty on server, from store on client",
      "    const envVars = isClient ? getClientEnvVars(getStore) : {}"
    ]
  },
  "CWE-191": {
    "cve": "CVE-2023-39350",
    "commit_url": "https://github.com/FreeRDP/FreeRDP/commit/e204fc8be5a372626b13f66daf2abafe71dbc2dc",
    "diff": []
  },
  "CWE-122": {
    "cve": "CVE-2024-56827",
    "commit_url": "https://github.com/uclouvain/openjpeg/commit/e492644fbded4c820ca55b5e50e598d346e850e8",
    "diff": [
      "        if (cstr_index->tile_index[tileno].tp_index) {"
    ]
  },
  "CWE-434": {
    "cve": "CVE-2025-61681",
    "commit_url": "https://github.com/xuemian168/kuno/commit/fc486b5c9091b607f82bf7b354d18f25204f7dc6",
    "diff": [
      "!/docs/CHANGELOG.md",
      "\tMaxFileSize = 100 * 1024 * 1024 // 100MB",
      "\t\"image/jpeg\": true,",
      "\t\"image/jpg\":  true,",
      "\t\"image/png\":  true,",
      "\t\"image/gif\":  true,",
      "\t\"image/webp\": true,",
      "\t// Generate unique filename",
      "\text := filepath.Ext(header.Filename)",
      "\t// Create the file",
      "\tdst, err := os.Create(filePath)",
      "\tif err != nil {",
      "\t\tfmt.Printf(\"Failed to create file %s: %v\\n\", filePath, err)",
      "\t\tc.JSON(http.StatusInternalServerError, gin.H{\"error\": \"Failed to create file\"})",
      "\t\treturn",
      "\t}",
      "\tdefer dst.Close()",
      "",
      "\t// Copy file content",
      "\tif _, err := io.Copy(dst, file); err != nil {",
      "\t\tFileSize:     header.Size,",
      "        return 'image/jpeg,image/jpg,image/png,image/gif,image/webp'",
      "        return 'image/jpeg,image/jpg,image/png,image/gif,image/webp,video/mp4,video/webm,video/ogg,video/avi,video/mov'"
    ]
  },
  "CWE-416": {
    "cve": "CVE-2024-43374",
    "commit_url": "https://github.com/vim/vim/commit/0a6e57b09bc8c76691b367a5babfb79b31b770e8",
    "diff": [
      "\t\t   && !(curwin->w_closing || curwin->w_buffer->b_locked > 0)",
      "\t\t    && !(wp->w_closing || wp->w_buffer->b_locked > 0)",
      "\t\tthe_curwin->w_closing = TRUE;",
      "\t\t    the_curwin->w_closing = FALSE;",
      "    int\t\tw_closing;\t    // window is being closed, don't let",
      "\t\t    curwin->w_closing = TRUE;",
      "\t\t    curwin->w_closing = FALSE;",
      "\t\t&& !(wp->w_closing || wp->w_buffer->b_locked > 0))",
      "\t\t    && !(wp->w_closing || wp->w_buffer->b_locked > 0))",
      "\twin->w_closing = TRUE;",
      "\t    win->w_closing = FALSE;",
      "    if (win->w_closing || (win->w_buffer != NULL",
      "\t    win->w_closing = TRUE;",
      "\t    win->w_closing = FALSE;",
      "\twin->w_closing = TRUE;",
      "\twin->w_closing = FALSE;",
      "    if (win->w_closing || (win->w_buffer != NULL"
    ]
  },
  "CWE-284": {
    "cve": "CVE-2024-30261",
    "commit_url": "https://github.com/nodejs/undici/commit/2b39440bd9ded841c93dd72138f3b1763ae26055",
    "diff": [
      "",
      "  // 3. If parsedMetadata is the empty set, return true.",
      "  // 4. Let metadata be the result of getting the strongest",
      "  const list = parsedMetadata.sort((c, d) => d.algo.localeCompare(c.algo))",
      "  // get the strongest algorithm",
      "  const strongest = list[0].algo",
      "  // get all entries that use the strongest algorithm; ignore weaker",
      "  const metadata = list.filter((item) => item.algo === strongest)",
      "  // 5. For each item in metadata:",
      "    let expectedValue = item.hash",
      "    if (expectedValue.endsWith('==')) {",
      "      expectedValue = expectedValue.slice(0, -2)",
      "    }",
      "",
      "    if (actualValue.endsWith('==')) {",
      "      actualValue = actualValue.slice(0, -2)",
      "    if (actualValue === expectedValue) {",
      "      return true",
      "    }",
      "",
      "    let actualBase64URL = crypto.createHash(algorithm).update(bytes).digest('base64url')",
      "",
      "    if (actualBase64URL.endsWith('==')) {",
      "      actualBase64URL = actualBase64URL.slice(0, -2)",
      "    }",
      "",
      "    if (actualBase64URL === expectedValue) {",
      "  // 6. Return false.",
      "const parseHashWithOptions = /((?<algo>sha256|sha384|sha512)-(?<hash>[A-z0-9+/]{1}.*={0,2}))( +[\\x21-\\x7e]?)?/i",
      "  const supportedHashes = crypto.getHashes()",
      "",
      "    if (parsedToken === null || parsedToken.groups === undefined) {",
      "    const algorithm = parsedToken.groups.algo",
      "    if (supportedHashes.includes(algorithm.toLowerCase())) {",
      "  normalizeMethodRecord"
    ]
  },
  "CWE-287": {
    "cve": "CVE-2023-28609",
    "commit_url": "https://github.com/ansible-semaphore/semaphore/commit/3e4a62b7f2b1ef0660c9fb839818a53c80a5a8b1",
    "diff": [
      "func authenticationHandler(w http.ResponseWriter, r *http.Request) {",
      "\t\t\treturn",
      "\t\t\treturn",
      "\t\t\treturn",
      "\t\t\treturn",
      "\t\t\treturn",
      "\t\t\treturn",
      "\t\t\treturn",
      "\t\treturn",
      "\t\t\treturn",
      "\t\tauthenticationHandler(w, r)",
      "\t\tnext.ServeHTTP(w, r)",
      "\t\t\tauthenticationHandler(w, r)",
      "\t\tnext.ServeHTTP(w, r)",
      "\t//updateAvailable, err := util.CheckUpdate()",
      "",
      "\t//if err != nil {",
      "\t//\thelpers.WriteError(w, err)",
      "\t//\treturn",
      "\t//}",
      "",
      "\t\t//\"update\":  updateAvailable,"
    ]
  },
  "CWE-200": {
    "cve": "CVE-2024-52513",
    "commit_url": "https://github.com/nextcloud/text/commit/ca24b25c93b81626b4e457c260243edeab5f1548",
    "diff": [
      "\t\t\t// Check if shareToken has access to document",
      "\t\t\tif ($this->rootFolder->getUserFolder($share->getShareOwner())->getFirstNodeById($documentId) === null) {"
    ]
  },
  "CWE-94": {
    "cve": "CVE-2024-6345",
    "commit_url": "https://github.com/pypa/setuptools/commit/88807c7062788254f654ea8c03427adc859321f0",
    "diff": [
      "                found = self._download_url(scheme.group(1), spec, tmpdir)",
      "    def _download_url(self, scheme, url, tmpdir):",
      "        # Download the file",
      "        #",
      "        if scheme == 'svn' or scheme.startswith('svn+'):",
      "            return self._download_svn(url, filename)",
      "        elif scheme == 'git' or scheme.startswith('git+'):",
      "            return self._download_git(url, filename)",
      "        elif scheme.startswith('hg+'):",
      "            return self._download_hg(url, filename)",
      "        elif scheme == 'file':",
      "            return urllib.request.url2pathname(urllib.parse.urlparse(url)[2])",
      "        else:",
      "            self.url_ok(url, True)  # raises error if not allowed",
      "            return self._attempt_download(url, filename)",
      "    def _download_svn(self, url, _filename):",
      "        raise DistutilsError(f\"Invalid config, SVN download is not supported: {url}\")",
      "",
      "    def _vcs_split_rev_from_url(url, pop_prefix=False):",
      "        scheme, netloc, path, query, frag = urllib.parse.urlsplit(url)",
      "        scheme = scheme.split('+', 1)[-1]",
      "        path = path.split('#', 1)[0]",
      "",
      "        rev = None",
      "        if '@' in path:",
      "            path, rev = path.rsplit('@', 1)",
      "",
      "        # Also, discard fragment",
      "        url = urllib.parse.urlunsplit((scheme, netloc, path, query, ''))",
      "",
      "        return url, rev",
      "",
      "    def _download_git(self, url, filename):",
      "        filename = filename.split('#', 1)[0]",
      "        url, rev = self._vcs_split_rev_from_url(url, pop_prefix=True)",
      "",
      "        self.info(\"Doing git clone from %s to %s\", url, filename)",
      "        os.system(\"git clone --quiet %s %s\" % (url, filename))",
      "",
      "        if rev is not None:",
      "            self.info(\"Checking out %s\", rev)",
      "            os.system(",
      "                \"git -C %s checkout --quiet %s\"",
      "                % (",
      "                    filename,",
      "                    rev,",
      "                )",
      "            )",
      "        return filename",
      "    def _download_hg(self, url, filename):",
      "        filename = filename.split('#', 1)[0]",
      "        url, rev = self._vcs_split_rev_from_url(url, pop_prefix=True)",
      "        self.info(\"Doing hg clone from %s to %s\", url, filename)",
      "        os.system(\"hg clone --quiet %s %s\" % (url, filename))",
      "",
      "        if rev is not None:",
      "            self.info(\"Updating to %s\", rev)",
      "            os.system(",
      "                \"hg --cwd %s up -C -r %s -q\"",
      "                % (",
      "                    filename,",
      "                    rev,",
      "                )",
      "            )",
      "",
      "        return filename",
      "from unittest import mock",
      "    def test_download_git_with_rev(self, tmpdir):",
      "        with mock.patch(\"os.system\") as os_system_mock:",
      "            result = index.download(url, str(tmpdir))",
      "        os_system_mock.assert_called()",
      "        expected_dir = str(tmpdir / 'project@master')",
      "        expected = (",
      "            'git clone --quiet ' 'https://github.example/group/project {expected_dir}'",
      "        ).format(**locals())",
      "        first_call_args = os_system_mock.call_args_list[0][0]",
      "        assert first_call_args == (expected,)",
      "        tmpl = 'git -C {expected_dir} checkout --quiet master'",
      "        expected = tmpl.format(**locals())",
      "        assert os_system_mock.call_args_list[1][0] == (expected,)",
      "        assert result == expected_dir",
      "",
      "    def test_download_git_no_rev(self, tmpdir):",
      "        with mock.patch(\"os.system\") as os_system_mock:",
      "            result = index.download(url, str(tmpdir))",
      "",
      "        os_system_mock.assert_called()",
      "",
      "        expected_dir = str(tmpdir / 'project')",
      "        expected = (",
      "            'git clone --quiet ' 'https://github.example/group/project {expected_dir}'",
      "        ).format(**locals())",
      "        os_system_mock.assert_called_once_with(expected)",
      "",
      "    def test_download_svn(self, tmpdir):",
      "            index.download(url, str(tmpdir))"
    ]
  },
  "CWE-400": {
    "cve": "CVE-2024-23835",
    "commit_url": "https://github.com/OISF/suricata/commit/86de7cffa7e8f06fe9d600127e7dabe89c7e81dd",
    "diff": [
      "use nom7::combinator::{all_consuming, cond, eof, map_parser, opt, peek, rest, verify};",
      "                    let (i, payload) = rest(i)?;",
      "                        identifier: pseudo_header.0,",
      "                        length: pseudo_header.1,",
      "            payload: bad_buf.to_vec(),"
    ]
  },
  "CWE-120": {
    "cve": "CVE-2024-40130",
    "commit_url": "https://github.com/open5gs/open5gs/commit/2f8ae91b0b9467f94f128090c88cae91bd73e008",
    "diff": [
      "    const char *argv_out[argc];",
      "    for (i = 0; argv[i]; i++) {",
      "    for (i = 0; argv[i]; i++) {",
      "    for (i = 0; argv[i]; i++) {",
      "    const char *argv_out[argc+4], *new_argv[argc+4];",
      "            &test_self()->nr_served_tai[index].list2.tai[0], sizeof(ogs_5gs_tai_t));",
      "",
      "        ogs_fatal(\"Not implmented EPC Indirect Tunnel\");",
      "        ogs_assert_if_reached();",
      "    int i, j;",
      "    SupportedTAItem = CALLOC(1, sizeof(NGAP_SupportedTAItem_t));",
      "        ogs_asn_uint24_to_OCTET_STRING(",
      "            test_self()->nr_served_tai[0].list2.tai[0].tac,",
      "            &SupportedTAItem->tAC);",
      "        ogs_asn_uint24_to_OCTET_STRING(",
      "            test_self()->nr_served_tai[0].list0.tai[0].tac[0],",
      "                &SupportedTAItem->tAC);",
      "    for (i = 0; i < test_self()->num_of_plmn_support; i++) {",
      "        plmn_id = &test_self()->plmn_support[i].plmn_id;",
      "        BroadcastPLMNItem = CALLOC(1, sizeof(NGAP_BroadcastPLMNItem_t));",
      "        ogs_asn_buffer_to_OCTET_STRING(",
      "                plmn_id, OGS_PLMN_ID_LEN, &BroadcastPLMNItem->pLMNIdentity);",
      "        for (j = 0; j < test_self()->plmn_support[i].num_of_s_nssai; j++) {",
      "            ogs_s_nssai_t *s_nssai = &test_self()->plmn_support[i].s_nssai[j];",
      "            SliceSupportItem = CALLOC(1, sizeof(NGAP_SliceSupportItem_t));",
      "            ogs_asn_uint8_to_OCTET_STRING(s_nssai->sst,",
      "                    &SliceSupportItem->s_NSSAI.sST);",
      "            if (s_nssai->sd.v != OGS_S_NSSAI_NO_SD_VALUE) {",
      "                SliceSupportItem->s_NSSAI.sD = CALLOC(1, sizeof(NGAP_SD_t));",
      "                ogs_asn_uint24_to_OCTET_STRING(",
      "                        s_nssai->sd, SliceSupportItem->s_NSSAI.sD);",
      "            ASN_SEQUENCE_ADD(&BroadcastPLMNItem->tAISliceSupportList.list,",
      "                            SliceSupportItem);",
      "        ASN_SEQUENCE_ADD(&SupportedTAItem->broadcastPLMNList.list,",
      "                BroadcastPLMNItem);",
      "    ASN_SEQUENCE_ADD(&SupportedTAList->list, SupportedTAItem);",
      "",
      "    int i, j;",
      "        SupportedTAItem = CALLOC(1, sizeof(NGAP_SupportedTAItem_t));",
      "            ogs_asn_uint24_to_OCTET_STRING(",
      "                test_self()->nr_served_tai[0].list2.tai[0].tac,",
      "                &SupportedTAItem->tAC);",
      "            ogs_asn_uint24_to_OCTET_STRING(",
      "                test_self()->nr_served_tai[0].list0.tai[0].tac[0],",
      "                    &SupportedTAItem->tAC);",
      "        for (i = 0; i < test_self()->num_of_plmn_support; i++) {",
      "            plmn_id = &test_self()->plmn_support[i].plmn_id;",
      "",
      "            BroadcastPLMNItem = CALLOC(1, sizeof(NGAP_BroadcastPLMNItem_t));",
      "",
      "            ogs_asn_buffer_to_OCTET_STRING(",
      "                    plmn_id, OGS_PLMN_ID_LEN, &BroadcastPLMNItem->pLMNIdentity);",
      "",
      "            for (j = 0; j < test_self()->plmn_support[i].num_of_s_nssai; j++) {",
      "                ogs_s_nssai_t *s_nssai =",
      "                    &test_self()->plmn_support[i].s_nssai[j];",
      "",
      "                SliceSupportItem = CALLOC(1, sizeof(NGAP_SliceSupportItem_t));",
      "                ogs_asn_uint8_to_OCTET_STRING(s_nssai->sst,",
      "                        &SliceSupportItem->s_NSSAI.sST);",
      "                if (s_nssai->sd.v != OGS_S_NSSAI_NO_SD_VALUE) {",
      "                    SliceSupportItem->s_NSSAI.sD = CALLOC(1, sizeof(NGAP_SD_t));",
      "                    ogs_asn_uint24_to_OCTET_STRING(",
      "                            s_nssai->sd, SliceSupportItem->s_NSSAI.sD);",
      "                ASN_SEQUENCE_ADD(&BroadcastPLMNItem->tAISliceSupportList.list,",
      "                                SliceSupportItem);",
      "            ASN_SEQUENCE_ADD(&SupportedTAItem->broadcastPLMNList.list,",
      "                    BroadcastPLMNItem);",
      "",
      "        ASN_SEQUENCE_ADD(&SupportedTAList->list, SupportedTAItem);",
      "    const char *argv_out[argc+2]; /* '-e error' is always added */",
      "    const char *argv_out[argc+2]; /* '-e error' is always added */",
      "    const char *argv_out[argc+2]; /* '-e error' is always added */",
      "    const char *argv_out[argc+2]; /* '-e error' is always added */"
    ]
  },
  "CWE-787": {
    "cve": "CVE-2023-4863",
    "commit_url": "https://github.com/webmproject/libwebp/commit/902bc9190331343b2017211debcec8d2ab87e17a",
    "diff": [
      "  HuffmanCode table[1 << LENGTHS_TABLE_BITS];",
      "  if (!VP8LBuildHuffmanTable(table, LENGTHS_TABLE_BITS,",
      "                             code_length_code_lengths,",
      "                             NUM_CODE_LENGTH_CODES)) {",
      "    p = &table[VP8LPrefetchBits(br) & LENGTHS_TABLE_MASK];",
      "                           int* const code_lengths, HuffmanCode* const table) {",
      "  HuffmanCode* huffman_tables = NULL;",
      "  HuffmanCode* huffman_table = NULL;",
      "  huffman_tables = (HuffmanCode*)WebPSafeMalloc(num_htree_groups * table_size,",
      "                                                sizeof(*huffman_tables));",
      "  if (htree_groups == NULL || code_lengths == NULL || huffman_tables == NULL) {",
      "  huffman_table = huffman_tables;",
      "        htrees[j] = huffman_table;",
      "        size = ReadHuffmanCode(alphabet_size, dec, code_lengths, huffman_table);",
      "          is_trivial_literal = (huffman_table->bits == 0);",
      "        total_size += huffman_table->bits;",
      "        huffman_table += size;",
      "  hdr->huffman_tables_ = huffman_tables;",
      "    WebPSafeFree(huffman_tables);",
      "  WebPSafeFree(hdr->huffman_tables_);",
      "  assert(dec->hdr_.huffman_tables_ != NULL);",
      "  HuffmanCode*    huffman_tables_;",
      "      if (root_table == NULL) continue;",
      "          table += table_size;",
      "          root_table[low].bits = (uint8_t)(table_bits + root_bits);",
      "          root_table[low].value = (uint16_t)((table - root_table) - low);",
      "        code.bits = (uint8_t)(len - root_bits);",
      "        code.value = (uint16_t)sorted[symbol++];",
      "        ReplicateValue(&table[key >> root_bits], step, table_size, code);",
      "int VP8LBuildHuffmanTable(HuffmanCode* const root_table, int root_bits,",
      "  int total_size;",
      "  if (root_table == NULL) {",
      "    total_size = BuildHuffmanTable(NULL, root_bits,",
      "                                   code_lengths, code_lengths_size, NULL);",
      "  } else if (code_lengths_size <= SORTED_SIZE_CUTOFF) {",
      "    total_size = BuildHuffmanTable(root_table, root_bits,",
      "                                   code_lengths, code_lengths_size, sorted);",
      "  } else {   // rare case. Use heap allocation.",
      "    total_size = BuildHuffmanTable(root_table, root_bits,",
      "                                   code_lengths, code_lengths_size, sorted);",
      "// If root_table is NULL, it returns 0 if a lookup cannot be built, something",
      "// > 0 otherwise (but not the table size).",
      "int VP8LBuildHuffmanTable(HuffmanCode* const root_table, int root_bits,"
    ]
  },
  "CWE-754": {
    "cve": "CVE-2025-53359",
    "commit_url": "https://github.com/rust-ethereum/ethereum/commit/2dd9d1d5d0936ec7350093ff3a5a7169a349db77",
    "diff": [
      "\t\tAuthorizationListItem, EIP7702Transaction, TransactionAction, TransactionV3,",
      "\t\t\t\ty_parity: false,",
      "\t\t\t\tr: H256::zero(),",
      "\t\t\t\ts: H256::zero(),",
      "\t\t\todd_y_parity: false,",
      "\t\t\tr: H256::zero(),",
      "\t\t\ts: H256::zero(),",
      "\t\t\todd_y_parity: false,",
      "\t\t\tr: H256::zero(),",
      "\t\t\ts: H256::zero(),",
      "use crate::{",
      "\ttransaction::{AccessList, TransactionAction},",
      "\tBytes,",
      "};",
      "\tpub odd_y_parity: bool,",
      "\tpub r: H256,",
      "\tpub s: H256,",
      "\t\ts.append(&self.odd_y_parity);",
      "\t\ts.append(&U256::from_big_endian(&self.r[..]));",
      "\t\ts.append(&U256::from_big_endian(&self.s[..]));",
      "\t\t\todd_y_parity: rlp.val_at(9)?,",
      "\t\t\tr: H256::from(rlp.val_at::<U256>(10)?.to_big_endian()),",
      "\t\t\ts: H256::from(rlp.val_at::<U256>(11)?.to_big_endian()),",
      "use crate::{transaction::TransactionAction, Bytes};",
      "\tpub odd_y_parity: bool,",
      "\tpub r: H256,",
      "\tpub s: H256,",
      "\t\ts.append(&self.odd_y_parity);",
      "\t\ts.append(&U256::from_big_endian(&self.r[..]));",
      "\t\ts.append(&U256::from_big_endian(&self.s[..]));",
      "\t\t\todd_y_parity: rlp.val_at(8)?,",
      "\t\t\tr: H256::from(rlp.val_at::<U256>(9)?.to_big_endian()),",
      "\t\t\ts: H256::from(rlp.val_at::<U256>(10)?.to_big_endian()),",
      "use crate::{",
      "\ttransaction::{AccessList, TransactionAction},",
      "\tBytes,",
      "\tpub y_parity: bool,",
      "\tpub r: H256,",
      "\tpub s: H256,",
      "\t\ts.append(&self.y_parity);",
      "\t\ts.append(&U256::from_big_endian(&self.r[..]));",
      "\t\ts.append(&U256::from_big_endian(&self.s[..]));",
      "\t\t\ty_parity: rlp.val_at(3)?,",
      "\t\t\tr: H256::from(rlp.val_at::<U256>(4)?.to_big_endian()),",
      "\t\t\ts: H256::from(rlp.val_at::<U256>(5)?.to_big_endian()),",
      "\t\tsignature_bytes[0..32].copy_from_slice(&self.r[..]);",
      "\t\tsignature_bytes[32..64].copy_from_slice(&self.s[..]);",
      "\t\tlet recovery_id = RecoveryId::try_from(if self.y_parity { 1u8 } else { 0u8 })",
      "\tpub odd_y_parity: bool,",
      "\tpub r: H256,",
      "\tpub s: H256,",
      "\t\ts.append(&self.odd_y_parity);",
      "\t\ts.append(&U256::from_big_endian(&self.r[..]));",
      "\t\ts.append(&U256::from_big_endian(&self.s[..]));",
      "\t\t\todd_y_parity: rlp.val_at(10)?,",
      "\t\t\tr: H256::from(rlp.val_at::<U256>(11)?.to_big_endian()),",
      "\t\t\ts: H256::from(rlp.val_at::<U256>(12)?.to_big_endian()),",
      "\t\t\ty_parity,",
      "\t\t\tr,",
      "\t\t\ts,",
      "\t\tlet auth_item = AuthorizationListItem {",
      "\t\t\tchain_id: 1,",
      "\t\t\taddress: Address::from_slice(&[0x42u8; 20]),",
      "\t\t\tnonce: U256::zero(),",
      "\t\t\ty_parity: false,",
      "\t\t\tr: H256::zero(), // Invalid r value (r cannot be zero)",
      "\t\t\ts: H256::zero(), // Invalid s value (s cannot be zero)",
      "\t\t};",
      "",
      "\t\t// This should return an error due to invalid signature",
      "\t\tlet result = auth_item.authorizing_address();",
      "\t\tassert!(result.is_err());",
      "\t\tassert_eq!(result.unwrap_err(), AuthorizationError::InvalidSignature);",
      "\t\tlet auth_item_high_values = AuthorizationListItem {",
      "\t\t\tchain_id: 1,",
      "\t\t\taddress: Address::from_slice(&[0x42u8; 20]),",
      "\t\t\tnonce: U256::zero(),",
      "\t\t\ty_parity: false,",
      "\t\t\tr: H256::from_slice(&[0xFF; 32]),",
      "\t\t\ts: H256::from_slice(&[0xFF; 32]),",
      "\t\t};",
      "",
      "\t\tlet result = auth_item_high_values.authorizing_address();",
      "\t\tassert!(result.is_err());",
      "\t\tassert_eq!(result.unwrap_err(), AuthorizationError::InvalidSignature);",
      "#[cfg_attr(feature = \"with-serde\", derive(serde::Serialize, serde::Deserialize))]",
      "mod eip1559;",
      "mod eip2930;",
      "mod eip7702;",
      "mod legacy;",
      "\teip1559::{EIP1559Transaction, EIP1559TransactionMessage},",
      "\teip2930::{AccessList, AccessListItem, EIP2930Transaction, EIP2930TransactionMessage},",
      "\teip7702::{",
      "\t\tAuthorizationList, AuthorizationListItem, EIP7702Transaction, EIP7702TransactionMessage,",
      "\t\tAUTHORIZATION_MAGIC, SET_CODE_TX_TYPE,",
      "\t},",
      "\tlegacy::{",
      "\t\tLegacyTransaction, LegacyTransactionMessage, TransactionAction, TransactionRecoveryId,",
      "\t\tTransactionSignature,",
      "\t},",
      "\tuse super::*;",
      "\t\t\tsignature: TransactionSignature::new(38, hex!(\"be67e0a07db67da8d446f76add590e54b6e92cb6b8f9835aeb67540579a27717\").into(), hex!(\"2d690516512020171c1ec870f6ff45398cc8609250326be89915fb538e7bd718\").into()).unwrap(),",
      "\t\t\todd_y_parity: false,",
      "\t\t\tr: hex!(\"36b241b061a36a32ab7fe86c7aa9eb592dd59018cd0443adc0903590c16b02b0\").into(),",
      "\t\t\ts: hex!(\"5edcc541b4741c5cc6dd347c5ed9577ef293a62787b4510465fadbfe39ee4094\").into(),",
      "\t\t\todd_y_parity: false,",
      "\t\t\tr: hex!(\"36b241b061a36a32ab7fe86c7aa9eb592dd59018cd0443adc0903590c16b02b0\").into(),",
      "\t\t\ts: hex!(\"5edcc541b4741c5cc6dd347c5ed9577ef293a62787b4510465fadbfe39ee4094\").into(),",
      "\t\t\t\ty_parity: false,",
      "\t\t\t\tr: hex!(\"36b241b061a36a32ab7fe86c7aa9eb592dd59018cd0443adc0903590c16b02b0\").into(),",
      "\t\t\t\ts: hex!(\"5edcc541b4741c5cc6dd347c5ed9577ef293a62787b4510465fadbfe39ee4094\").into(),",
      "\t\t\todd_y_parity: false,",
      "\t\t\tr: hex!(\"36b241b061a36a32ab7fe86c7aa9eb592dd59018cd0443adc0903590c16b02b0\").into(),",
      "\t\t\ts: hex!(\"5edcc541b4741c5cc6dd347c5ed9577ef293a62787b4510465fadbfe39ee4094\").into(),"
    ]
  },
  "CWE-190": {
    "cve": "CVE-2023-46246",
    "commit_url": "https://github.com/vim/vim/commit/9198c1f2b1ddecde22af918541e0de2a32f0f45a",
    "diff": [
      "\tsemsg(_(e_trailing_characters_str), end);",
      "\t    *num2 = (int)num;"
    ]
  },
  "CWE-354": {
    "cve": "CVE-2023-34459",
    "commit_url": "https://github.com/OpenZeppelin/openzeppelin-contracts/commit/4d2383e17186be3e8ccf5a442e9686ecc7de1c55",
    "diff": [
      "        require(leavesLen + proof.length - 1 == totalHashes, \"MerkleProof: invalid multiproof\");",
      "        require(leavesLen + proof.length - 1 == totalHashes, \"MerkleProof: invalid multiproof\");",
      "require('@openzeppelin/test-helpers');",
      "",
      "const { expect } = require('chai');",
      ""
    ]
  },
  "CWE-119": {
    "cve": "CVE-2025-11012",
    "commit_url": "https://github.com/BehaviorTree/BehaviorTree.CPP/commit/cb6c7514efa628adb8180b58b4c9ccdebbe096e3",
    "diff": [
      "  char error_msgs_buffer[2048];",
      "  auto result =",
      "      lexy::parse<BT::Grammar::stmt>(input, ErrorReport().to(error_msgs_buffer));",
      "  char error_msgs_buffer[2048];",
      "  auto result =",
      "      lexy::parse<BT::Grammar::stmt>(input, ErrorReport().to(error_msgs_buffer));"
    ]
  },
  "CWE-617": {
    "cve": "CVE-2025-8836",
    "commit_url": "https://github.com/jasper-software/jasper/commit/79185d32d7a444abae441935b20ae4676b3513d4",
    "diff": [
      "\t\t\tprcwidthexpn = jpc_floorlog2(atoi(jas_tvparser_getval(tvp)));",
      "\t\t\tprcheightexpn = jpc_floorlog2(atoi(jas_tvparser_getval(tvp)));",
      "\t\t\ttccp->cblkwidthexpn =",
      "\t\t\t  jpc_floorlog2(atoi(jas_tvparser_getval(tvp)));",
      "\t\t\ttccp->cblkheightexpn =",
      "\t\t\t  jpc_floorlog2(atoi(jas_tvparser_getval(tvp)));",
      "\t\t\t\t\t\tif ((len = jpc_bitstream_getbits(inb, cblk->numlenbits + jpc_floorlog2(n))) < 0) {"
    ]
  },
  "CWE-476": {
    "cve": "CVE-2023-2609",
    "commit_url": "https://github.com/vim/vim/commit/d1ae8366aff286d41e7f5bc513cc0a1af5130aad",
    "diff": [
      "\tif (reg->y_size == 0)"
    ]
  },
  "CWE-362": {
    "cve": "CVE-2025-48880",
    "commit_url": "https://github.com/freescout-help-desk/freescout/commit/3f5bb2841f7de3303bc3cb00930a28440754d122",
    "diff": [
      "                if (!$response['msg'] && $user->isAdmin()) {",
      "                    $admins_count = User::where('role', User::ROLE_ADMIN)->count();",
      "                    if ($admins_count < 2) {",
      "                        $response['msg'] = __('Administrator can not be deleted');",
      "                    }",
      "                }"
    ]
  },
  "CWE-732": {
    "cve": "CVE-2023-23939",
    "commit_url": "https://github.com/Azure/setup-kubectl/commit/d449d75495d2b9d1463555bb00ca3dca77a42ab6",
    "diff": [
      "        expect(fs.chmodSync).toBeCalledWith(path.join('pathToCachedTool', 'kubectl.exe'), '777');",
      "        expect(fs.chmodSync).toBeCalledWith(path.join('pathToCachedTool', 'kubectl.exe'), '777');",
      "    fs.chmodSync(kubectlPath, '777');\r"
    ]
  },
  "CWE-703": {
    "cve": "CVE-2025-54134",
    "commit_url": "https://github.com/haxtheweb/haxcms-nodejs/commit/e9773d1996233f9bafb06832b8220ec2a98bab34",
    "diff": [
      "    let site = await HAXCMS.loadSite(req.query['siteName']);",
      "    if (site && site.siteDirectory) {",
      "      let search = (typeof req.query['filename'] !== 'undefined') ? req.query['filename'] : '';",
      "      // build files directory path",
      "      let siteFilePath = path.join(site.siteDirectory, 'files');",
      "      let handle;",
      "      if (handle = fs.readdirSync(siteFilePath)) {",
      "        handle.forEach(file => {",
      "          if (",
      "              file != \".\" &&",
      "              file != \"..\" &&",
      "              file != '.gitkeep' &&",
      "              file != '.DS_Store'",
      "          ) {",
      "            // ensure this is a file",
      "              fs.lstatSync(siteFilePath + '/' + file).isFile()",
      "              // ensure this is a file and if we are searching for results then return only exact ones",
      "              if (search == \"\" || file.indexOf(search) !== -1) {",
      "                let fullUrl = '/files/' + file;",
      "                // multiple sites then append the base url to site management area",
      "                if (HAXCMS.operatingContext == 'multisite') {",
      "                  fullUrl = HAXCMS.basePath +",
      "                  HAXCMS.sitesDirectory + '/' +",
      "                  site.manifest.metadata.site.name + '/files/' + file",
      "                files.push({",
      "                  'path' : 'files/' + file,",
      "                  'fullUrl' : fullUrl,",
      "                  'url' : 'files/' + file,",
      "                  'mimetype' : mime.getType(siteFilePath + '/' + file),",
      "                  'name' : file",
      "                });",
      "            } else {",
      "                // @todo maybe step into directories?",
      "          }",
      "        });"
    ]
  },
  "CWE-668": {
    "cve": "CVE-2024-51754",
    "commit_url": "https://github.com/twigphp/Twig/commit/2bb8c2460a2c519c498df9b643d5277117155a73",
    "diff": [
      "            $node->setNode($name, new CheckToStringNode($expr));",
      "        $twig = $this->getEnvironment(true, [], ['index' => $template], [], ['upper'], ['Twig\\Tests\\Extension\\FooObject' => 'getAnotherFooObject'], [], ['random']);",
      "            $this->fail('Sandbox throws a SecurityError exception if an unallowed method (__toString()) is called in the template');"
    ]
  },
  "CWE-834": {
    "cve": "CVE-2023-5632",
    "commit_url": "https://github.com/eclipse/mosquitto/commit/18bad1ff32435e523d7507e9b2ce0010124a8f2d",
    "diff": [
      "\tmux__add_out(mosq);"
    ]
  },
  "CWE-444": {
    "cve": "CVE-2025-49005",
    "commit_url": "https://github.com/vercel/next.js/commit/ec202eccf05820b60c6126d6411fe16766ecc066",
    "diff": [
      "      res.appendHeader('vary', `${NEXT_URL}`)",
      "    // For other cases such as App Router requests or RSC requests we don't need to set vary header since we already",
      "    // have the _rsc query with the unique hash value.",
      "  it('should preserve custom vary header', async () => {",
      "  it('should preserve middleware vary header', async () => {"
    ]
  },
  "CWE-522": {
    "cve": "CVE-2024-47081",
    "commit_url": "https://github.com/psf/requests/commit/96ba401c1296ab1dda74a2365ef36d88f7d144ef",
    "diff": [
      "",
      "        # Strip port numbers from netloc. This weird `if...encode`` dance is",
      "        # used for Python 3.2, which doesn't support unicode literals.",
      "        splitstr = b\":\"",
      "        if isinstance(url, str):",
      "            splitstr = splitstr.decode(\"ascii\")",
      "        host = ri.netloc.split(splitstr)[0]"
    ]
  },
  "CWE-843": {
    "cve": "CVE-2024-6119",
    "commit_url": "https://github.com/openssl/openssl/commit/7dfcee2cd2a63b2c64b9b4b0850be64cb695b0a0",
    "diff": [
      "            if ((gen->type == GEN_OTHERNAME) && (check_type == GEN_EMAIL)) {",
      "                if (OBJ_obj2nid(gen->d.otherName->type_id) ==",
      "                    NID_id_on_SmtpUTF8Mailbox) {",
      "                    san_present = 1;",
      "",
      "                    /*",
      "                     * If it is not a UTF8String then that is unexpected and we",
      "                     * treat it as no match",
      "                     */",
      "                    if (gen->d.otherName->value->type == V_ASN1_UTF8STRING) {",
      "                        cstr = gen->d.otherName->value->value.utf8string;",
      "",
      "                        /* Positive on success, negative on error! */",
      "                        if ((rv = do_check_string(cstr, 0, equal, flags,",
      "                                                chk, chklen, peername)) != 0)",
      "                            break;",
      "                    }",
      "                } else",
      "            } else {",
      "                if ((gen->type != check_type) && (gen->type != GEN_OTHERNAME))",
      "            }",
      "            san_present = 1;",
      "            if (check_type == GEN_EMAIL)",
      "            else if (check_type == GEN_DNS)",
      "            else",
      "plan tests => 12;"
    ]
  },
  "CWE-835": {
    "cve": "CVE-2025-48879",
    "commit_url": "https://github.com/OctoPrint/OctoPrint/commit/c9c35c17bd820f19c6b12e6c0359fc0cfdd0c1ec",
    "diff": [
      "            while len(self._buffer):"
    ]
  },
  "CWE-824": {
    "cve": "CVE-2023-4508",
    "commit_url": "https://github.com/gerbv/gerbv/commit/5517e22250e935dc7f86f64ad414aeae3dbcb36a",
    "diff": [
      "\t\t",
      "    /* Store filename info fd for further use */",
      "    fd->filename = g_strdup(filename);",
      "    ",
      "    g_free(fd->filename);",
      "               example_am_test"
    ]
  },
  "CWE-345": {
    "cve": "CVE-2023-42816",
    "commit_url": "https://github.com/kyverno/kyverno/commit/80d139bb5d1d9d7e907abe851b97dc73821a5be2",
    "diff": [
      "// +kubebuilder:validation:Enum=Cosign;NotaryV2",
      "\tCosign   ImageVerificationType = \"Cosign\"",
      "\tNotaryV2 ImageVerificationType = \"NotaryV2\"",
      "\t// are Cosign and NotaryV2. By default Cosign is used if a type is not specified.",
      "\t// +kubebuilder:validation:Required",
      "// +kubebuilder:validation:Enum=Cosign;NotaryV2",
      "\tCosign   ImageVerificationType = \"Cosign\"",
      "\tNotaryV2 ImageVerificationType = \"NotaryV2\"",
      "\t// are Cosign and NotaryV2. By default Cosign is used if a type is not specified.",
      "                              required:",
      "                              - predicateType",
      "                              The allowed options are Cosign and NotaryV2. By default",
      "                            - NotaryV2",
      "                                  required:",
      "                                  - predicateType",
      "                                  validation. The allowed options are Cosign and NotaryV2.",
      "                                - NotaryV2",
      "                              required:",
      "                              - predicateType",
      "                              The allowed options are Cosign and NotaryV2. By default",
      "                            - NotaryV2",
      "                                  required:",
      "                                  - predicateType",
      "                                  validation. The allowed options are Cosign and NotaryV2.",
      "                                - NotaryV2",
      "                              required:",
      "                              - predicateType",
      "                              The allowed options are Cosign and NotaryV2. By default",
      "                            - NotaryV2",
      "                                  required:",
      "                                  - predicateType",
      "                                  validation. The allowed options are Cosign and NotaryV2.",
      "                                - NotaryV2",
      "                              required:",
      "                              - predicateType",
      "                              The allowed options are Cosign and NotaryV2. By default",
      "                            - NotaryV2",
      "                                  required:",
      "                                  - predicateType",
      "                                  validation. The allowed options are Cosign and NotaryV2.",
      "                                - NotaryV2",
      "                              required:",
      "                              - predicateType",
      "                              The allowed options are Cosign and NotaryV2. By default",
      "                            - NotaryV2",
      "                                  required:",
      "                                  - predicateType",
      "                                  validation. The allowed options are Cosign and NotaryV2.",
      "                                - NotaryV2",
      "                              required:",
      "                              - predicateType",
      "                              The allowed options are Cosign and NotaryV2. By default",
      "                            - NotaryV2",
      "                                  required:",
      "                                  - predicateType",
      "                                  validation. The allowed options are Cosign and NotaryV2.",
      "                                - NotaryV2",
      "                              required:",
      "                              - predicateType",
      "                              The allowed options are Cosign and NotaryV2. By default",
      "                            - NotaryV2",
      "                                  required:",
      "                                  - predicateType",
      "                                  validation. The allowed options are Cosign and NotaryV2.",
      "                                - NotaryV2",
      "                              required:",
      "                              - predicateType",
      "                              The allowed options are Cosign and NotaryV2. By default",
      "                            - NotaryV2",
      "                                  required:",
      "                                  - predicateType",
      "                                  validation. The allowed options are Cosign and NotaryV2.",
      "                                - NotaryV2",
      "                              required:",
      "                              - predicateType",
      "                              The allowed options are Cosign and NotaryV2. By default",
      "                            - NotaryV2",
      "                                  required:",
      "                                  - predicateType",
      "                                  validation. The allowed options are Cosign and NotaryV2.",
      "                                - NotaryV2",
      "                              required:",
      "                              - predicateType",
      "                              The allowed options are Cosign and NotaryV2. By default",
      "                            - NotaryV2",
      "                                  required:",
      "                                  - predicateType",
      "                                  validation. The allowed options are Cosign and NotaryV2.",
      "                                - NotaryV2",
      "                              required:",
      "                              - predicateType",
      "                              The allowed options are Cosign and NotaryV2. By default",
      "                            - NotaryV2",
      "                                  required:",
      "                                  - predicateType",
      "                                  validation. The allowed options are Cosign and NotaryV2.",
      "                                - NotaryV2",
      "                              required:",
      "                              - predicateType",
      "                              The allowed options are Cosign and NotaryV2. By default",
      "                            - NotaryV2",
      "                                  required:",
      "                                  - predicateType",
      "                                  validation. The allowed options are Cosign and NotaryV2.",
      "                                - NotaryV2",
      "<p>PredicateType defines the type of Predicate contained within the Statement.</p>",
      "are Cosign and NotaryV2. By default Cosign is used if a type is not specified.</p>",
      "are Cosign and NotaryV2. By default Cosign is used if a type is not specified.</p>",
      "\tgithub.com/google/go-containerregistry v0.14.0",
      "\toras.land/oras-go/v2 v2.2.0",
      "\tcloud.google.com/go/compute v1.19.0 // indirect",
      "\tgithub.com/Microsoft/go-winio v0.6.0 // indirect",
      "\tgithub.com/docker/cli v23.0.2+incompatible // indirect",
      "\tgithub.com/docker/docker v23.0.3+incompatible // indirect",
      "\tgithub.com/klauspost/compress v1.16.3 // indirect",
      "\tgithub.com/opencontainers/go-digest v1.0.0 // indirect",
      "\tgolang.org/x/oauth2 v0.6.0 // indirect",
      "cloud.google.com/go/compute v1.19.0 h1:+9zda3WGgW1ZSTlVppLCYFIr48Pa35q1uG2N1itbCEQ=",
      "cloud.google.com/go/compute v1.19.0/go.mod h1:rikpw2y+UMidAe9tISo04EHNOIf42RLYF/q8Bs93scU=",
      "github.com/Microsoft/go-winio v0.6.0 h1:slsWYD/zyx7lCXoZVlvQrj0hPTM1HI4+v1sIda2yDvg=",
      "github.com/Microsoft/go-winio v0.6.0/go.mod h1:cTAf44im0RAYeL23bpB+fzCyDH2MJiz2BO69KH/soAE=",
      "github.com/docker/cli v23.0.2+incompatible h1:Yj4wkrNtyCNLCMobKDYzEUIsbtMbfAulkHMH75/ecik=",
      "github.com/docker/cli v23.0.2+incompatible/go.mod h1:JLrzqnKDaYBop7H2jaqPtU4hHvMKP+vjCwu2uszcLI8=",
      "github.com/docker/docker v23.0.3+incompatible h1:9GhVsShNWz1hO//9BNg/dpMnZW25KydO4wtVxWAIbho=",
      "github.com/docker/docker v23.0.3+incompatible/go.mod h1:eEKB0N0r5NX/I1kEveEz05bcu8tLC/8azJZsviup8Sk=",
      "github.com/google/go-containerregistry v0.14.0 h1:z58vMqHxuwvAsVwvKEkmVBz2TlgBgH5k6koEXBtlYkw=",
      "github.com/google/go-containerregistry v0.14.0/go.mod h1:aiJ2fp/SXvkWgmYHioXnbMdlgB8eXiiYOY55gfN91Wk=",
      "github.com/klauspost/compress v1.16.3 h1:XuJt9zzcnaz6a16/OU53ZjWp/v7/42WcR5t2a0PcNQY=",
      "github.com/klauspost/compress v1.16.3/go.mod h1:ntbaceVETuRiXiv4DpjP66DpAtAGkEQskQzEyD//IeE=",
      "golang.org/x/oauth2 v0.6.0 h1:Lh8GPgSKBfWSwFvtuWOfeI3aAAnbXTSutYxJiOJFgIw=",
      "golang.org/x/oauth2 v0.6.0/go.mod h1:ycmewcwgD4Rpr3eZJLSB4Kyyljb3qDh40vJ8STE5HKw=",
      "oras.land/oras-go/v2 v2.2.0 h1:E1fqITD56Eg5neZbxBtAdZVgDHD6wBabJo6xESTcQyo=",
      "oras.land/oras-go/v2 v2.2.0/go.mod h1:pXjn0+KfarspMHHNR3A56j3tgvr+mxArHuI8qVn59v8=",
      "\tif opts.PredicateType == \"\" {",
      "\t\tmatch, predicateType, err := matchPredicateType(signature, opts.PredicateType)",
      "\t\t\tlogger.V(4).Info(\"predicateType doesn't match, continue\", \"expected\", opts.PredicateType, \"received\", predicateType)",
      "func matchPredicateType(sig oci.Signature, expectedPredicateType string) (bool, string, error) {",
      "\tif expectedPredicateType != \"\" {",
      "\t\t\treturn false, \"\", fmt.Errorf(\"failed to decode predicateType: %w\", err)",
      "\t\tif pType, ok := statement[\"predicateType\"]; ok {",
      "\t\t\tif pType.(string) == expectedPredicateType {",
      "\tif statement.PredicateType != attestation.CosignCustomProvenanceV01 {",
      "\tif statement.PredicateType != attestation.CosignCustomProvenanceV01 {",
      "\t\t\"resolvedImage\": fmt.Sprintf(\"%s@%s\", desc.Ref.Context().Name(), desc.Digest.String()),",
      "\t\t\"registry\":      desc.Ref.Context().RegistryStr(),",
      "\t\t\"repository\":    desc.Ref.Context().RepositoryStr(),",
      "\t\t\"identifier\":    desc.Ref.Identifier(),",
      "\t\truleCopy.VerifyImages[i].Attestations = nil",
      "\tfor i := range rule.VerifyImages {",
      "\t\truleCopy.VerifyImages[i].Attestations = rule.VerifyImages[i].Attestations",
      "\t\"github.com/kyverno/kyverno/pkg/notaryv2\"",
      "\t\tpredicateType := s[\"predicateType\"].(string)",
      "\t\tif attestation.PredicateType == \"\" {",
      "\t\t\treturn engineapi.RuleFail(iv.rule.Name, engineapi.ImageVerify, path+\": missing predicateType\"), \"\"",
      "\t\tiv.logger.V(4).Info(\"attestation checks passed\", \"path\", path, \"image\", imageInfo.String(), \"predicateType\", attestation.PredicateType)",
      "\tcase kyvernov1.NotaryV2:",
      "\t\treturn iv.buildNotaryV2Verifier(attestor, imageVerify, image)",
      "func (iv *ImageVerifier) buildNotaryV2Verifier(",
      "\treturn notaryv2.NewVerifier(), opts, path",
      "\tif attestation.PredicateType == \"\" {",
      "\t\treturn fmt.Errorf(\"a predicateType is required\")",
      "\tstatements = statementsByPredicate[attestation.PredicateType]",
      "\t\tiv.logger.Info(\"no attestations found for predicate\", \"type\", attestation.PredicateType, \"predicates\", types, \"image\", imageInfo.String())",
      "\t\treturn fmt.Errorf(\"attestions not found for predicate type %s\", attestation.PredicateType)",
      "\t\t\treturn fmt.Errorf(\"attestation checks failed for %s and predicate %s: %s\", imageInfo.String(), attestation.PredicateType, msg)",
      "package notaryv2",
      "package notaryv2",
      "",
      "import (",
      "\t\"bytes\"",
      "\t\"context\"",
      "",
      "\t\"github.com/go-logr/logr\"",
      "\t\"github.com/kyverno/kyverno/pkg/images\"",
      "\t\"github.com/kyverno/kyverno/pkg/logging\"",
      "\t_ \"github.com/notaryproject/notation-core-go/signature/cose\"",
      "\t_ \"github.com/notaryproject/notation-core-go/signature/jws\"",
      "\t\"github.com/notaryproject/notation-go\"",
      "\t\"github.com/notaryproject/notation-go/verifier\"",
      "\t\"github.com/notaryproject/notation-go/verifier/trustpolicy\"",
      "\t\"github.com/pkg/errors\"",
      "\t\"github.com/sigstore/sigstore/pkg/cryptoutils\"",
      "\t\"go.uber.org/multierr\"",
      ")",
      "",
      "func NewVerifier() images.ImageVerifier {",
      "\treturn &notaryV2Verifier{",
      "\t\tlog: logging.WithName(\"NotaryV2\"),",
      "\t}",
      "}",
      "",
      "type notaryV2Verifier struct {",
      "\tlog logr.Logger",
      "}",
      "",
      "func (v *notaryV2Verifier) VerifySignature(ctx context.Context, opts images.Options) (*images.Response, error) {",
      "\tv.log.V(2).Info(\"verifying image\", \"reference\", opts.ImageRef)",
      "",
      "\tcertsPEM := combineCerts(opts)",
      "\tcerts, err := cryptoutils.LoadCertificatesFromPEM(bytes.NewReader([]byte(certsPEM)))",
      "\tif err != nil {",
      "\t\treturn nil, errors.Wrapf(err, \"failed to parse certificates\")",
      "\t}",
      "",
      "\ttrustStore := NewTrustStore(\"kyverno\", certs)",
      "\tpolicyDoc := v.buildPolicy()",
      "\tnotationVerifier, err := verifier.New(policyDoc, trustStore, nil)",
      "\tif err != nil {",
      "\t\treturn nil, errors.Wrapf(err, \"failed to created verifier\")",
      "\t}",
      "",
      "\trepo, parsedRef, err := parseReference(ctx, opts.ImageRef, opts.RegistryClient)",
      "\tif err != nil {",
      "\t\treturn nil, errors.Wrapf(err, \"failed to parse image reference: %s\", opts.ImageRef)",
      "\t}",
      "",
      "\tdigest, err := parsedRef.Digest()",
      "\tif err != nil {",
      "\t\treturn nil, errors.Wrapf(err, \"failed to fetch digest\")",
      "\t}",
      "",
      "\tref := parsedRef.String()",
      "\tremoteVerifyOptions := notation.RemoteVerifyOptions{",
      "\t\tArtifactReference:    ref,",
      "\t\tMaxSignatureAttempts: 10,",
      "\t}",
      "",
      "\ttargetDesc, outcomes, err := notation.Verify(context.TODO(), notationVerifier, repo, remoteVerifyOptions)",
      "\tif err != nil {",
      "\t\treturn nil, errors.Wrapf(err, \"failed to verify %s\", ref)",
      "\t}",
      "",
      "\tif err := v.verifyOutcomes(outcomes); err != nil {",
      "\t\treturn nil, err",
      "\t}",
      "",
      "\tif targetDesc.Digest != digest {",
      "\t\treturn nil, errors.Errorf(\"digest mismatch\")",
      "\t}",
      "",
      "\tv.log.V(2).Info(\"verified image\", \"type\", targetDesc.MediaType, \"digest\", targetDesc.Digest, \"size\", targetDesc.Size)",
      "",
      "\tresp := &images.Response{",
      "\t\tDigest:     targetDesc.Digest.String(),",
      "\t\tStatements: nil,",
      "\t}",
      "",
      "\treturn resp, nil",
      "}",
      "",
      "func combineCerts(opts images.Options) string {",
      "\tcerts := opts.Cert",
      "\tif opts.CertChain != \"\" {",
      "\t\tif certs != \"\" {",
      "\t\t\tcerts = certs + \"\\n\"",
      "\t\t}",
      "",
      "\t\tcerts = certs + opts.CertChain",
      "\t}",
      "",
      "\treturn certs",
      "}",
      "",
      "func (v *notaryV2Verifier) buildPolicy() *trustpolicy.Document {",
      "\treturn &trustpolicy.Document{",
      "\t\tVersion: \"1.0\",",
      "\t\tTrustPolicies: []trustpolicy.TrustPolicy{",
      "\t\t\t{",
      "\t\t\t\tName:                  \"kyverno\",",
      "\t\t\t\tRegistryScopes:        []string{\"*\"},",
      "\t\t\t\tSignatureVerification: trustpolicy.SignatureVerification{VerificationLevel: trustpolicy.LevelStrict.Name},",
      "\t\t\t\tTrustStores:           []string{\"ca:kyverno\"},",
      "\t\t\t\tTrustedIdentities:     []string{\"*\"},",
      "\t\t\t},",
      "\t\t},",
      "\t}",
      "}",
      "",
      "func (v *notaryV2Verifier) verifyOutcomes(outcomes []*notation.VerificationOutcome) error {",
      "\tvar errs []error",
      "\tfor _, outcome := range outcomes {",
      "\t\tif outcome.Error != nil {",
      "\t\t\terrs = append(errs, outcome.Error)",
      "\t\t\tcontinue",
      "\t\t}",
      "",
      "\t\tcontent := outcome.EnvelopeContent.Payload.Content",
      "\t\tcontentType := outcome.EnvelopeContent.Payload.ContentType",
      "",
      "\t\tv.log.Info(\"content\", \"type\", contentType, \"data\", content)",
      "\t}",
      "",
      "\treturn multierr.Combine(errs...)",
      "}",
      "",
      "func (v *notaryV2Verifier) FetchAttestations(ctx context.Context, opts images.Options) (*images.Response, error) {",
      "\treturn nil, errors.Errorf(\"not implemented\")",
      "}",
      "package notaryv2",
      "",
      "import (",
      "\t\"context\"",
      "\t\"strings\"",
      "",
      "\t\"github.com/kyverno/kyverno/pkg/registryclient\"",
      "\tnotationregistry \"github.com/notaryproject/notation-go/registry\"",
      "\tocispec \"github.com/opencontainers/image-spec/specs-go/v1\"",
      "\t\"github.com/pkg/errors\"",
      "\t\"oras.land/oras-go/v2/registry\"",
      "\t\"oras.land/oras-go/v2/registry/remote\"",
      "\t\"oras.land/oras-go/v2/registry/remote/auth\"",
      ")",
      "",
      "func parseReference(ctx context.Context, ref string, registryClient registryclient.Client) (notationregistry.Repository, registry.Reference, error) {",
      "\tparsedRef, err := registry.ParseReference(ref)",
      "\tif err != nil {",
      "\t\treturn nil, registry.Reference{}, errors.Wrapf(err, \"failed to parse registry reference %s\", ref)",
      "\t}",
      "",
      "\tauthClient, plainHTTP, err := getAuthClient(ctx, parsedRef, registryClient)",
      "\tif err != nil {",
      "\t\treturn nil, registry.Reference{}, err",
      "\t}",
      "",
      "\trepo, err := remote.NewRepository(ref)",
      "\tif err != nil {",
      "\t\treturn nil, registry.Reference{}, errors.Wrapf(err, \"failed to initialize repository\")",
      "\t}",
      "",
      "\trepo.PlainHTTP = plainHTTP",
      "\trepo.Client = authClient",
      "\trepository := notationregistry.NewRepository(repo)",
      "",
      "\tparsedRef, err = resolveDigest(repository, parsedRef)",
      "\tif err != nil {",
      "\t\treturn nil, registry.Reference{}, errors.Wrapf(err, \"failed to resolve digest\")",
      "\t}",
      "",
      "\treturn repository, parsedRef, nil",
      "}",
      "",
      "type imageResource struct {",
      "\tref registry.Reference",
      "}",
      "",
      "func (ir *imageResource) String() string {",
      "\treturn ir.ref.String()",
      "}",
      "",
      "func (ir *imageResource) RegistryStr() string {",
      "\treturn ir.ref.Registry",
      "}",
      "",
      "func getAuthClient(ctx context.Context, ref registry.Reference, rc registryclient.Client) (*auth.Client, bool, error) {",
      "\tif err := rc.RefreshKeychainPullSecrets(ctx); err != nil {",
      "\t\treturn nil, false, errors.Wrapf(err, \"failed to refresh image pull secrets\")",
      "\t}",
      "",
      "\tauthn, err := rc.Keychain().Resolve(&imageResource{ref})",
      "\tif err != nil {",
      "\t\treturn nil, false, errors.Wrapf(err, \"failed to resolve auth for %s\", ref.String())",
      "\t}",
      "",
      "\tauthConfig, err := authn.Authorization()",
      "\tif err != nil {",
      "\t\treturn nil, false, errors.Wrapf(err, \"failed to get auth config for %s\", ref.String())",
      "\t}",
      "",
      "\tcredentials := auth.Credential{",
      "\t\tUsername:     authConfig.Username,",
      "\t\tPassword:     authConfig.Password,",
      "\t\tAccessToken:  authConfig.IdentityToken,",
      "\t\tRefreshToken: authConfig.RegistryToken,",
      "\t}",
      "",
      "\tauthClient := &auth.Client{",
      "\t\tCredential: func(ctx context.Context, registry string) (auth.Credential, error) {",
      "\t\t\tswitch registry {",
      "\t\t\tdefault:",
      "\t\t\t\treturn credentials, nil",
      "\t\t\t}",
      "\t\t},",
      "\t\tCache:    auth.NewCache(),",
      "\t\tClientID: \"notation\",",
      "\t}",
      "",
      "\tauthClient.SetUserAgent(\"kyverno.io\")",
      "\treturn authClient, false, nil",
      "}",
      "",
      "func resolveDigest(repo notationregistry.Repository, ref registry.Reference) (registry.Reference, error) {",
      "\tif isDigestReference(ref.String()) {",
      "\t\treturn ref, nil",
      "\t}",
      "",
      "\t// Resolve tag reference to digest reference.",
      "\tmanifestDesc, err := getManifestDescriptorFromReference(repo, ref.String())",
      "\tif err != nil {",
      "\t\treturn registry.Reference{}, err",
      "\t}",
      "",
      "\tref.Reference = manifestDesc.Digest.String()",
      "\treturn ref, nil",
      "}",
      "",
      "func isDigestReference(reference string) bool {",
      "\tparts := strings.SplitN(reference, \"/\", 2)",
      "\tif len(parts) == 1 {",
      "\t\treturn false",
      "\t}",
      "",
      "\tindex := strings.Index(parts[1], \"@\")",
      "\treturn index != -1",
      "}",
      "",
      "func getManifestDescriptorFromReference(repo notationregistry.Repository, reference string) (ocispec.Descriptor, error) {",
      "\tref, err := registry.ParseReference(reference)",
      "\tif err != nil {",
      "\t\treturn ocispec.Descriptor{}, err",
      "\t}",
      "",
      "\treturn repo.Resolve(context.Background(), ref.ReferenceOrDefault())",
      "}",
      "apiVersion: kyverno.io/v1",
      "kind: Policy",
      "  conditions:",
      "    - reason: Succeeded",
      "      status: \"True\"",
      "      type: Ready"
    ]
  },
  "CWE-401": {
    "cve": "CVE-2025-64329",
    "commit_url": "https://github.com/containerd/containerd/commit/083b53cd6f19b5de7717b0ce92c11bdf95e612df",
    "diff": [
      "func (c *ContainerIO) Attach(opts AttachOptions) {",
      "\t\t<-close",
      "\t\tlog.L.Infof(\"Attach stream %q closed\", key)",
      "\tcntr.IO.Attach(opts)"
    ]
  },
  "CWE-193": {
    "cve": "CVE-2025-43971",
    "commit_url": "https://github.com/osrg/gobgp/commit/08a001e06d90e8bcc190084c66992f46f62c0986",
    "diff": [
      "\tif len(data[1:]) < int(softwareVersionLen) || softwareVersionLen > 64 {"
    ]
  },
  "CWE-908": {
    "cve": "CVE-2025-55198",
    "commit_url": "https://github.com/helm/helm/commit/ec5f59e2db56533d042a124f5bae54dd87b558e6",
    "diff": [
      "\t\t\t\tchild := iv[\"child\"].(string)",
      "\t\t\t\tparent := iv[\"parent\"].(string)"
    ]
  },
  "CWE-415": {
    "cve": "CVE-2023-26545",
    "commit_url": "https://github.com/torvalds/linux/commit/fda6c89fe3d9aca073495a664e1d5aea28cd4377",
    "diff": []
  },
  "CWE-134": {
    "cve": "CVE-2025-48388",
    "commit_url": "https://github.com/freescout-help-desk/freescout/commit/eab97711027fff4bce90ccd2e189cbc184fa0370",
    "diff": [
      "",
      "    /**",
      "     * Handle an incoming request.",
      "     *",
      "     * @param  \\Illuminate\\Http\\Request  $request",
      "     * @param  \\Closure  $next",
      "     * @return mixed",
      "     *",
      "     * @throws \\Illuminate\\Session\\TokenMismatchException",
      "     */",
      "    public function handle($request, $next)",
      "    {",
      "        if (",
      "            $this->isReading($request) ||",
      "            $this->runningUnitTests() ||",
      "            $this->inExceptArray($request) ||",
      "            $this->tokensMatch($request)",
      "        ) {",
      "        \t// Do not send XSRF-TOKEN as it's not needed.",
      "        \t// https://github.com/laravel/ideas/issues/873",
      "            //return $this->addCookieToResponse($request, $next($request));",
      "            return $next($request);",
      "        }",
      "",
      "        throw new TokenMismatchException;",
      "    }",
      "        // default-src 'self'; img-src 'self' data:; font-src 'self' data:; style-src 'self' 'unsafe-inline'; form-action 'self'; frame-src https://recaptcha.net; connect-src https://recaptcha.net;",
      "        return \"<meta http-equiv=\\\"Content-Security-Policy\\\" content=\\\"script-src 'self' 'nonce-\".$nonce.\"' \"",
      "            .config('app.csp_script_src').' '.\\Eventy::filter('csp.script_src', '').\";\"",
      "        if (is_array($data) || is_object($data)) {",
      "            return serialize($data);",
      "    'version' => '1.8.177',",
      "    'same_site' => env('SESSION_SAME_SITE', 'lax'),",
      "        if (!$newLocale || in_array($newLocale, $locales)) {",
      "            return $this->addCookieToResponse($request, $next($request));",
      "    props = props || {path:\"/\", SameSite:'Lax'};",
      "        $php_path = preg_replace(\"#[ ;\\$<>:&\\|]#\", '', $php_path);"
    ]
  },
  "CWE-369": {
    "cve": "CVE-2025-55212",
    "commit_url": "https://github.com/ImageMagick/ImageMagick/commit/5f0bcf986b8b5e90567750d31a37af502b73f2af",
    "diff": [
      "  if ((columns == 0) || (rows == 0))",
      "    ThrowImageException(ImageError,\"NegativeOrZeroImageSize\");",
      "      x_factor=(ssize_t) image->columns/(ssize_t) columns;",
      "      y_factor=(ssize_t) image->rows/(ssize_t) rows;"
    ]
  },
  "CWE-276": {
    "cve": "CVE-2024-34455",
    "commit_url": "https://github.com/buildroot/buildroot/commit/0b2967e15800421efbdfe3a7a6061cf6bd84134d",
    "diff": [
      "tmpfs\t\t/dev/shm\ttmpfs\tmode=0777\t0\t0"
    ]
  },
  "CWE-295": {
    "cve": "CVE-2025-62371",
    "commit_url": "https://github.com/opensearch-project/data-prepper/commit/98fcf0d0ff9c18f1f7501e11dbed918814724b99",
    "diff": [
      "    final SSLContext sslContext = certPath != null ? getCAStrategy(certPath) : getTrustAllStrategy();",
      "    httpClientBuilder.setSSLContext(sslContext);",
      "      return new AwsSdk2Transport(createSdkHttpClient(), HttpHost.create(hosts.get(0)).getHostName(),",
      "    TrustManager[] trustManagers = createTrustManagers(certPath);",
      "    apacheHttpClientBuilder.tlsTrustManagersProvider(() -> trustManagers);",
      "  private static TrustManager[] createTrustManagers(final Path certPath) {",
      "    } else {",
      "        asyncClientBuilder.tlsTrustManagersProvider(() -> trustManagers);",
      "        if (Objects.nonNull(certPath)) {",
      "        } else if (Objects.nonNull(connectionConfiguration.getCertificate())) {",
      "            if (PemObjectValidator.isPemObject(connectionConfiguration.getCertificate())) {",
      "                return TrustStoreProvider.createTrustManager(connectionConfiguration.getCertificate());",
      "                return TrustStoreProvider.createTrustManager(Path.of(connectionConfiguration.getCertificate()));",
      "            }",
      "        } else {",
      "        if (Objects.nonNull(certPath)) {",
      "        } else if (Objects.nonNull(connectionConfiguration.getCertificate())) {",
      "            if (PemObjectValidator.isPemObject(connectionConfiguration.getCertificate())) {",
      "                return TrustStoreProvider.createSSLContext(connectionConfiguration.getCertificate());",
      "            return TrustStoreProvider.createSSLContextWithTrustAllStrategy();",
      "        when(apacheHttpClientBuilder.tlsTrustManagersProvider(any())).thenReturn(apacheHttpClientBuilder);",
      "        verify(apacheHttpClientBuilder).tlsTrustManagersProvider(any());"
    ]
  },
  "CWE-772": {
    "cve": "CVE-2024-52303",
    "commit_url": "https://github.com/aio-libs/aiohttp/commit/bc15db61615079d1b6327ba42c682f758fa96936",
    "diff": [
      "@lru_cache(None)",
      "            if not self._has_legacy_middlewares:",
      "                handler = _build_middlewares(handler, match_info.apps)",
      "from typing import Any",
      "from aiohttp import web"
    ]
  },
  "CWE-288": {
    "cve": "CVE-2024-31463",
    "commit_url": "https://github.com/metal3-io/ironic-image/commit/48e40bd30d49aefabac6fc80204a8650b13d10b4",
    "diff": [
      "export IRONIC_PRIVATE_PORT=${IRONIC_PRIVATE_PORT:-6388}",
      "export IRONIC_INSPECTOR_PRIVATE_PORT=${IRONIC_INSPECTOR_PRIVATE_PORT:-5049}"
    ]
  },
  "CWE-909": {
    "cve": "CVE-2024-53845",
    "commit_url": "https://github.com/espressif/esp-idf/commit/4f85a2726e04b737c8646d865b44ddd837b703db",
    "diff": [
      "Subproject commit 3c0c961eaa925626666400b451028f6512e2bad9",
      "The SmartConfig\\ :sup:`TM` is a provisioning technology developed by TI to connect a new Wi-Fi device to a Wi-Fi network. It uses a mobile app to broadcast the network credentials from a smartphone, or a tablet, to an un-provisioned Wi-Fi device.",
      ".. include:: ../../../en/api-reference/network/esp_smartconfig.rst"
    ]
  },
  "CWE-924": {
    "cve": "CVE-2024-52288",
    "commit_url": "https://github.com/goToMain/libosdp/commit/298576d9214b48214092eebdd892ec77be085e5a",
    "diff": [
      "\t\t\tLOG_WRN(\"Out of order CMD_SCRYPT; has CP gone rogue?\");"
    ]
  },
  "CWE-212": {
    "cve": "CVE-2025-53886",
    "commit_url": "https://github.com/directus/directus/commit/22be460c76957708d67fdd52846a9ad1cbb083fb",
    "diff": [
      "\t\tcontext: Record<string, unknown>,"
    ]
  },
  "CWE-189": {
    "cve": "CVE-2025-9688",
    "commit_url": "https://github.com/mupen64plus/mupen64plus-core/commit/3984137fc0c44110f1ef876adb008885b05a6e18",
    "diff": [
      "            /* make sure we don't overflow the buffer */",
      "            if (is_viewer->buffer_pos + word > IS_BUFFER_SIZE)",
      "                DebugMessage(M64MSG_WARNING, \"IS64: prevented buffer overflow, cleared buffer\");"
    ]
  }
}